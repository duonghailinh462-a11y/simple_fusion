import os
import sys
import time
import multiprocessing
import copy
import json
from collections import defaultdict, deque
from statistics import mean, median
sys.path.append('/usr/local/lynxi/sdk/sdk-samples/python')

import numpy as np
import cv2
from ctypes import *
import ctypes
from dataclasses import dataclass
from typing import List, Tuple, Optional, Set, Dict


# --- æ€§èƒ½ç›‘è§†å™¨ç±» ---
import logging

logger = logging.getLogger(__name__)

class PerformanceMonitor:
    """ç®€åŒ–çš„æ€§èƒ½ç›‘è§†å™¨ - åªä¿ç•™åŸºæœ¬è®¡æ•°å’ŒFPSç»Ÿè®¡"""
    
    def __init__(self):
        self.counters = defaultdict(int)
        self.timers = {}
        self.start_time = time.time()
        self.last_report_time = time.time()
        self.report_interval = 10.0
        
        logger.info("æ€§èƒ½ç›‘è§†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def start_timer(self, name: str):
        """å¼€å§‹è®¡æ—¶"""
        self.timers[name] = time.time()
    
    def end_timer(self, name: str) -> float:
        """ç»“æŸè®¡æ—¶å¹¶è¿”å›è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰"""
        if name not in self.timers:
            return 0.0
        elapsed = (time.time() - self.timers[name]) * 1000
        del self.timers[name]
        return elapsed
    
    def add_counter(self, name: str, value: int = 1):
        """å¢åŠ è®¡æ•°å™¨"""
        self.counters[name] += value
    
    def record_queue_stats(self, camera_id: int, queue_size: int, operation: str):
        """è®°å½•é˜Ÿåˆ—çŠ¶æ€ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        pass  # å¦‚æœéœ€è¦å¯ä»¥æ·»åŠ ç®€å•çš„æ—¥å¿—
    
    def record_fusion_stats(self, operation: str, duration_ms: float, details: dict = None):
        """è®°å½•èåˆç»Ÿè®¡ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        pass  # å¦‚æœéœ€è¦å¯ä»¥æ·»åŠ ç®€å•çš„æ—¥å¿—
    
    def get_performance_report(self) -> str:
        """ç”Ÿæˆç®€åŒ–çš„æ€§èƒ½æŠ¥å‘Š"""
        current_time = time.time()
        elapsed = current_time - self.last_report_time
        
        if elapsed < self.report_interval:
            return ""
        
        total_elapsed = current_time - self.start_time
        self.last_report_time = current_time
        
        # ç®€å•çš„FPSè®¡ç®—
        fps = self.counters.get('frames_processed', 0) / total_elapsed if total_elapsed > 0 else 0
        sync_fps = self.counters.get('frames_synchronized', 0) / total_elapsed if total_elapsed > 0 else 0
        
        report = []
        report.append(f"\n{'='*60}")
        report.append(f"ğŸ“Š æ€§èƒ½æŠ¥å‘Š (è¿è¡Œæ—¶é—´: {total_elapsed:.1f}s)")
        report.append(f"{'='*60}")
        report.append(f"å¤„ç†é€Ÿåº¦: {fps:.2f} FPS (åŒæ­¥: {sync_fps:.2f} FPS)")
        report.append(f"æ€»å¸§æ•°: {self.counters.get('frames_processed', 0)}")
        report.append(f"åŒæ­¥å¸§æ•°: {self.counters.get('frames_synchronized', 0)}")
        report.append(f"æ£€æµ‹æ•°: {self.counters.get('detections_processed', 0)}")
        report.append(f"BEVè½¬æ¢: {self.counters.get('bev_conversions', 0)}")
        report.append(f"MQTTå‘é€: {self.counters.get('mqtt_sends', 0)} (å¤±è´¥: {self.counters.get('mqtt_failures', 0)})")
        report.append(f"{'='*60}")
        
        return "\n".join(report)
    
    def reset_counters(self):
        """é‡ç½®è®¡æ•°å™¨"""
        self.counters.clear()
        self.start_time = time.time()
        self.last_report_time = time.time()
# --- é…ç½®ç±» (æŒ‰èŒè´£æ‹†åˆ†) ---

@dataclass
class ImageConfig:
    """å›¾åƒå’Œè§†é¢‘ç›¸å…³é…ç½®"""
    WIDTH: int = 1280
    HEIGHT: int = 720
    FPS: int = 25

@dataclass
class TrackingConfig:
    """ç›®æ ‡è·Ÿè¸ªç›¸å…³é…ç½®"""
    TRACK_THRESH: float = 0.3
    MATCH_THRESH: float = 0.6
    MIN_FRAMES_THRESHOLD: int = 10
    IOU_THRESHOLD: float = 0.5
    TOLERANCE_FRAMES: int = 60

@dataclass
class VehicleConfig:
    """è½¦è¾†ç±»åˆ«ç›¸å…³é…ç½®"""
    VEHICLE_CLASSES: List[str] = None
    EXCLUDE_CLASSES: List[str] = None
    SIMILAR_CLASSES: Dict[str, List[str]] = None
    
    def __post_init__(self):
        if self.VEHICLE_CLASSES is None:
            self.VEHICLE_CLASSES = [
                'mini_truck', 'truck', 'bus', 'van', 'car', 'ambulance',
                'fireEngine', 'schoolBus', 'tanker', 'muckTruck',
                'concreteTruck', 'policeCar'
            ]
        if self.EXCLUDE_CLASSES is None:
            self.EXCLUDE_CLASSES = ["person", "electric_vehicle", "bike", "tricycle", "engineer"]
        if self.SIMILAR_CLASSES is None:
            self.SIMILAR_CLASSES = {
                'mini_truck': ['truck', 'van', 'car'],
                'truck': ['mini_truck', 'van', 'car'],
                'van': ['mini_truck', 'truck', 'car'],
                'car': ['van', 'mini_truck', 'truck'],
                'bus': ['truck', 'van', 'car'],
            }


@dataclass
class FusionConfig:
    """è·¨æ‘„åƒå¤´èåˆç›¸å…³é…ç½®"""
    TIME_WINDOW: int = 80
    TEMPORAL_WINDOW_MAX: int = 225
    BASE_SPATIAL_THRESHOLD: float = 400.0
    
    # æŒ‰å¯¹é˜Ÿåˆ—èåˆé…ç½®
    ENABLE_SEQ_MATCHING: bool = True
    RESERVATION_TTL_FRAMES: int = 60
    MAX_RETENTION_FRAMES: int = 200
    TIME_WINDOW_STRICT: int = 30
    TIME_WINDOW_FLEXIBLE: int = 60
    
    # ğŸ”§ èåˆæ—¶é—´çª—å£
    FUSION_TIME_WINDOW: int = 60
    
    # C2 å‡ºå£åŒºåŸŸ (BEVåæ ‡)
    C2_EXIT_REGION_C3: np.ndarray = None
    C2_EXIT_REGION_C1: np.ndarray = None
    
    # é›·è§†èåˆåŒºåŸŸ (åƒç´ åæ ‡) - ç”¨äºæ ‡è®°å¯è¿›è¡Œé›·è§†èåˆçš„åŒºåŸŸ
    RADAR_VISION_FUSION_AREAS: Dict[int, np.ndarray] = None
    
    
    def __post_init__(self):
        if self.C2_EXIT_REGION_C3 is None:
            self.C2_EXIT_REGION_C3 = np.array(
                [[1022, 654], [1092, 605], [1082, 589], [1011, 642]], dtype=np.int32
            )
        if self.C2_EXIT_REGION_C1 is None:
            self.C2_EXIT_REGION_C1 = np.array(
                [[1022, 654], [1011, 642], [871, 735], [884, 757]], dtype=np.int32
            )
        if self.RADAR_VISION_FUSION_AREAS is None:
            self.RADAR_VISION_FUSION_AREAS = {
                1: np.array([[110, 429], [0, 536], [0, 720], [1280, 720], [1280, 458]], dtype=np.int32),
                2: np.array([[0, 720], [1280, 720], [1280, 418], [109, 432]], dtype=np.int32),
                3: np.array([[328, 472], [186, 720], [1033, 720], [985, 468]], dtype=np.int32),
            }

@dataclass
class TimestampConfig:
    """æ—¶é—´æˆ³ç›¸å…³é…ç½®"""
    CAMERA_START_DATETIMES: Dict[int, str] = None
    
    def __post_init__(self):
        if self.CAMERA_START_DATETIMES is None:
            self.CAMERA_START_DATETIMES = {
                1: "2025-11-21 11:59:12.135",
                2: "2025-11-21 11:59:12.150",
                3: "2025-11-21 11:59:12.143",
            }

class _Config:
    """ç»Ÿä¸€çš„é…ç½®ç®¡ç†ç±» - ä½¿ç”¨ç»„åˆæ¨¡å¼"""
    def __init__(self):
        self.image = ImageConfig()
        self.tracking = TrackingConfig()
        self.vehicle = VehicleConfig()
        self.fusion = FusionConfig()
        self.timestamp = TimestampConfig()
    
    # ä¸ºäº†å‘åå…¼å®¹ï¼Œæä¾›å±æ€§è®¿é—®
    @property
    def IMAGE_WIDTH(self): return self.image.WIDTH
    @property
    def IMAGE_HEIGHT(self): return self.image.HEIGHT
    @property
    def FPS(self): return self.image.FPS
    @property
    def TRACK_THRESH(self): return self.tracking.TRACK_THRESH
    @property
    def MATCH_THRESH(self): return self.tracking.MATCH_THRESH
    @property
    def MIN_FRAMES_THRESHOLD(self): return self.tracking.MIN_FRAMES_THRESHOLD
    @property
    def IOU_THRESHOLD(self): return self.tracking.IOU_THRESHOLD
    @property
    def TOLERANCE_FRAMES(self): return self.tracking.TOLERANCE_FRAMES
    @property
    def VEHICLE_CLASSES(self): return self.vehicle.VEHICLE_CLASSES
    @property
    def EXCLUDE_CLASSES(self): return self.vehicle.EXCLUDE_CLASSES
    @property
    def SIMILAR_CLASSES(self): return self.vehicle.SIMILAR_CLASSES
    @property
    def TIME_WINDOW(self): return self.fusion.TIME_WINDOW
    @property
    def TEMPORAL_WINDOW_MAX(self): return self.fusion.TEMPORAL_WINDOW_MAX
    @property
    def BASE_SPATIAL_THRESHOLD(self): return self.fusion.BASE_SPATIAL_THRESHOLD
    @property
    def ENABLE_SEQ_MATCHING(self): return self.fusion.ENABLE_SEQ_MATCHING
    @property
    def RESERVATION_TTL_FRAMES(self): return self.fusion.RESERVATION_TTL_FRAMES
    @property
    def MAX_RETENTION_FRAMES(self): return self.fusion.MAX_RETENTION_FRAMES
    @property
    def TIME_WINDOW_STRICT(self): return self.fusion.TIME_WINDOW_STRICT
    @property
    def TIME_WINDOW_FLEXIBLE(self): return self.fusion.TIME_WINDOW_FLEXIBLE
    @property
    def FUSION_TIME_WINDOW(self): return self.fusion.FUSION_TIME_WINDOW
    @property
    def PIXEL_BOTTOM_THRESHOLD(self): return self.fusion.PIXEL_BOTTOM_THRESHOLD
    @property
    def PIXEL_TOP_THRESHOLD(self): return self.fusion.PIXEL_TOP_THRESHOLD
    @property
    def C2_EXIT_REGION_C3(self): return self.fusion.C2_EXIT_REGION_C3
    @property
    def C2_EXIT_REGION_C1(self): return self.fusion.C2_EXIT_REGION_C1
    @property
    def RADAR_VISION_FUSION_AREAS(self): return self.fusion.RADAR_VISION_FUSION_AREAS
    @property
    def CAMERA_START_DATETIMES(self): return self.timestamp.CAMERA_START_DATETIMES

# çŸ©é˜µå’ŒåŒºåŸŸé…ç½®
CAMERA_MATRICES = {
    1: np.array([
        [3.57185777, -95.12052479, 4179.24844873],
        [3.46221359, -30.18092945, -4782.56623337],
        [0.00086667, -0.07779328, 1.00000000]
    ], dtype=np.float64),
    2: np.array([
        [-3.14205205, -15.41287574, -466.38259912],
        [-3.41382642, -24.02931190, 3191.87948399],
        [-0.00259235, -0.02359469, 1.00000000]
    ], dtype=np.float64),
    3: np.array([
        [2.30699835, -25.77644591, -1583.82133879],
        [-0.42448874, -13.71274357, -988.28445704],
        [0.00112695, -0.03632265, 1.00000000]
    ], dtype=np.float64),
}

# ğŸ”§ æ–°å¢ï¼šBEVåˆ°ä¸–ç•Œç±³åˆ¶åæ ‡çš„å˜æ¢çŸ©é˜µ
BEV_TO_WORLD_METER_MATRIX = np.array([
    [1.32977514e-01, -1.04276598e-04, -1.50540001e+02],
    [1.45689395e-03, -1.33712569e-01, 7.61259809e+01],
    [-1.97872483e-06, -2.12579392e-05, 1.00000000e+00]
], dtype=np.float64)

# ğŸ”§ æ–°å¢ï¼šBEVåˆ°åœ°ç†åæ ‡çš„å˜æ¢çŸ©é˜µï¼ˆä½¿ç”¨BEV_TO_WORLD_METER_MATRIXä½œä¸ºåŸºç¡€ï¼‰
BEV_TO_GEO_MATRIX = BEV_TO_WORLD_METER_MATRIX

# ğŸ”§ æ–°å¢ï¼šåœ°ç†åæ ‡åŸç‚¹ (å‚è€ƒç‚¹)
# è¿™æ˜¯ calculate_geo.py ä¸­ä½¿ç”¨çš„ç¬¬ä¸€ä¸ªç‚¹åæ ‡
GEO_ORIGIN_LON = 113.584439426
GEO_ORIGIN_LAT = 23.530769118

# ğŸ”§ æ–°å¢ï¼šåœ°çƒç›¸å…³å¸¸æ•°ç”¨äºç»çº¬åº¦è½¬æ¢
import math
EARTH_RADIUS = 6378137.0  # åœ°çƒåŠå¾„ (ç±³)
METERS_PER_DEG_LAT = (math.pi / 180.0) * EARTH_RADIUS
METERS_PER_DEG_LON = (math.pi / 180.0) * EARTH_RADIUS * math.cos(math.radians(GEO_ORIGIN_LAT))

PUBLIC_AREA_BEV = np.array([[1075, 606], [1066, 575], [850, 747], [877, 760]], dtype=np.int32)

# YOLOv5 ç±»åˆ«åç§°
NAMES = [
    'mini_truck','truck','bus','van','car','person','bike','electric_vehicle',
    'tricycle','engineer','ambulance','fireEngine','schoolBus','tanker','muckTruck',
    'concreteTruck','policeCar'
]

# --- å‡ ä½•å’Œæ£€æµ‹å·¥å…·ç±» ---
class GeometryUtils:
    @staticmethod
    def project_pixel_to_bev(H: np.ndarray, u: float, v: float) -> Optional[Tuple[float, float]]:
        """å•ä¸ªåƒç´ åˆ°BEVçš„è½¬æ¢"""
        p = np.array([u, v, 1.0])
        q = H @ p
        if abs(q[2]) < 1e-8: return None
        x, y = q[0] / q[2], q[1] / q[2]
        return (x, y)


    @staticmethod
    def bev_to_geo(x_bev: float, y_bev: float) -> Optional[Tuple[float, float]]:
        """BEVåƒç´  -> ä¸–ç•Œç±³åˆ¶åæ ‡ -> åœ°ç†åæ ‡ (ç»çº¬åº¦)"""
        try:
            # æ­¥éª¤1: BEVåƒç´  -> ä¸–ç•Œç±³åˆ¶åæ ‡
            p = np.array([x_bev, y_bev, 1.0])
            q = BEV_TO_GEO_MATRIX @ p
            q /= q[2]
            x_meters = q[0]  # ç›¸å¯¹äºåŸç‚¹çš„Xåç§» (ç±³)
            y_meters = q[1]  # ç›¸å¯¹äºåŸç‚¹çš„Yåç§» (ç±³)
            
            # æ­¥éª¤2: ä¸–ç•Œç±³åˆ¶åæ ‡ -> åœ°ç†åæ ‡ (ç»çº¬åº¦)
            # (ç±³ / æ¯åº¦ç±³æ•°) + åŸç‚¹åº¦æ•°
            lon = (x_meters / METERS_PER_DEG_LON) + GEO_ORIGIN_LON
            lat = (y_meters / METERS_PER_DEG_LAT) + GEO_ORIGIN_LAT
            
            return lon, lat
        except: 
            return None


    @staticmethod
    def calculate_iou(box1: List[float], box2: List[float]) -> float:
        x1_1, y1_1, x2_1, y2_1 = box1
        x1_2, y1_2, x2_2, y2_2 = box2
        x1_i, y1_i = max(x1_1, x1_2), max(y1_1, y1_2)
        x2_i, y2_i = min(x2_1, x2_2), min(y2_1, y2_2)
        if x2_i <= x1_i or y2_i <= y1_i: return 0.0
        intersection = (x2_i - x1_i) * (y2_i - y1_i)
        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
        union = area1 + area2 - intersection
        return intersection / union if union > 0 else 0.0

    @staticmethod
    def is_in_public_area(bev_point: Tuple[float, float]) -> bool:
        return cv2.pointPolygonTest(PUBLIC_AREA_BEV, bev_point, False) >= 0
    
    @staticmethod
    def is_in_radar_vision_fusion_area(pixel_point: Tuple[int, int], camera_id: int) -> bool:
        """æ£€æŸ¥åƒç´ ç‚¹æ˜¯å¦åœ¨è¯¥æ‘„åƒå¤´çš„é›·è§†èåˆåŒºåŸŸå†…"""
        # è·å–Configå®ä¾‹çš„èåˆåŒºåŸŸé…ç½®
        fusion_areas = Config.RADAR_VISION_FUSION_AREAS
        if not fusion_areas or camera_id not in fusion_areas:
            return False
        fusion_area = fusion_areas[camera_id]
        return cv2.pointPolygonTest(fusion_area, pixel_point, False) >= 0

class DetectionUtils:
    @staticmethod
    def is_class_compatible(class1: str, class2: str) -> bool:
        if class1 == class2: return True
        return (class1 in Config.SIMILAR_CLASSES and 
                class2 in Config.SIMILAR_CLASSES[class1])

    @staticmethod
    def non_max_suppression(detections: List[dict], 
                          iou_threshold: float = None) -> List[dict]:
        if iou_threshold is None:
            iou_threshold = Config.IOU_THRESHOLD
        if not detections: return detections
        detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)
        keep = []
        for det in detections:
            should_keep = True
            for kept_det in keep:
                if DetectionUtils.is_class_compatible(det['class'], kept_det['class']):
                    iou = GeometryUtils.calculate_iou(det['box'], kept_det['box'])
                    if iou > iou_threshold:
                        should_keep = False; break
            if should_keep: keep.append(det)
        return keep

    @staticmethod
    def is_turn_left(trajectory: List[Tuple[int, int]]) -> bool:
        if len(trajectory) < 2: return False
        start = np.array(trajectory[0])
        # ç®€åŒ–å·¦è½¬åˆ¤æ–­ï¼šå¦‚æœèµ·å§‹ç‚¹åœ¨å›¾åƒåº•éƒ¨ï¼Œåˆ™å¯èƒ½ä¸ºå·¦è½¬
        return start[1] >= Config.IMAGE_HEIGHT * 0.7 
        
# --- å¹³æ»‘æ»¤æ³¢å™¨ç±» ---
class SmoothingFilter:
    """
    å¯¹ç›®æ ‡çš„BEVåæ ‡è¿›è¡Œå¹³æ»‘å¤„ç†ã€‚
    """
    def __init__(self, history_len: int = 10, alpha: float = 0.5):
        # å­˜å‚¨æ¯ä¸ªç›®æ ‡ (track_id) çš„BEVåæ ‡å†å²
        self.bev_history = defaultdict(lambda: deque(maxlen=history_len))
        # æŒ‡æ•°å¹³æ»‘çš„æƒé‡å› å­ (0 < alpha < 1)ï¼Œæ•°å€¼è¶Šå°è¶Šå¹³æ»‘
        self.alpha = alpha
        
    def _sliding_average(self, track_id: int, current_bev: Tuple[float, float]) -> Tuple[float, float]:
        """æ»‘åŠ¨å¹³å‡å¹³æ»‘ (Moving Average)"""
        self.bev_history[track_id].append(current_bev)
        
        history = self.bev_history[track_id]
        if len(history) < 2:
            return current_bev
            
        # è®¡ç®—å†å²ç‚¹çš„å¹³å‡å€¼
        avg_x = sum(p[0] for p in history) / len(history)
        avg_y = sum(p[1] for p in history) / len(history)
        
        return (avg_x, avg_y)

    def _exponential_smoothing(self, track_id: int, current_bev: Tuple[float, float]) -> Tuple[float, float]:
        """æŒ‡æ•°å¹³æ»‘ (Exponential Smoothing)"""
        history_deque = self.bev_history[track_id]
        
        if not history_deque:
            # ç¬¬ä¸€æ¬¡æµ‹é‡ï¼Œç›´æ¥ä½¿ç”¨å½“å‰å€¼ä½œä¸ºå¹³æ»‘å€¼
            smoothed_bev = current_bev
        else:
            last_smoothed_bev = history_deque[-1]
            
            # P'_t = alpha * P_t + (1 - alpha) * P'_{t-1}
            smoothed_x = self.alpha * current_bev[0] + (1 - self.alpha) * last_smoothed_bev[0]
            smoothed_y = self.alpha * current_bev[1] + (1 - self.alpha) * last_smoothed_bev[1]
            smoothed_bev = (smoothed_x, smoothed_y)

        history_deque.append(smoothed_bev)
        return smoothed_bev
    
    def apply_smoothing(self, track_id: int, current_bev: Tuple[float, float], method: str = 'exponential') -> Tuple[float, float]:
        """åº”ç”¨å¹³æ»‘ç®—æ³•å¹¶è¿”å›å¹³æ»‘åçš„BEVåæ ‡"""
        if method == 'sliding':
            return self._sliding_average(track_id, current_bev)
        else: # é»˜è®¤ä¸ºæŒ‡æ•°å¹³æ»‘ï¼Œé€šå¸¸æ•ˆæœæ›´å¥½
            return self._exponential_smoothing(track_id, current_bev)

    def remove_track(self, track_id: int):
        """ç§»é™¤ä¸å†æ´»è·ƒçš„ç›®æ ‡çš„å†å²è®°å½•"""
        self.bev_history.pop(track_id, None)


# ============================================================================
# ğŸ”§ æ—¶é—´æˆ³æä¾›å™¨ä½¿ç”¨ç¤ºä¾‹
# ============================================================================
# 
# åœ¨ä½ çš„ä¸»ç¨‹åºä¸­ï¼Œåˆå§‹åŒ–æ—¶é—´æˆ³æä¾›å™¨ä¹‹å‰ï¼Œå…ˆè®¾ç½®æ‘„åƒå¤´çš„èµ·å§‹æ—¶é—´ï¼š
#
# ç¤ºä¾‹ä»£ç ï¼š
# --------
# from ffmpeg_timestamp_sync import FFmpegTimeStampProvider
#
# # æ–¹æ³•1ï¼šæ‰¹é‡è®¾ç½®æ‰€æœ‰æ‘„åƒå¤´çš„èµ·å§‹æ—¶é—´
# FFmpegTimeStampProvider.set_all_camera_start_datetimes(Config.CAMERA_START_DATETIMES)
#
# # æ–¹æ³•2ï¼šå•ä¸ªè®¾ç½®ï¼ˆå¯é€‰ï¼‰
# # FFmpegTimeStampProvider.set_camera_start_datetime(1, "2025-11-21 11:18:09.304")
# # FFmpegTimeStampProvider.set_camera_start_datetime(2, "2025-11-21 11:18:09.500")
# # FFmpegTimeStampProvider.set_camera_start_datetime(3, "2025-11-21 11:18:10.000")
#
# # ç„¶ååˆ›å»ºæ—¶é—´æˆ³æä¾›å™¨å®ä¾‹
# ts_provider_1 = FFmpegTimeStampProvider("path/to/video1.mp4", camera_id=1, fps=25)
# ts_provider_2 = FFmpegTimeStampProvider("path/to/video2.mp4", camera_id=2, fps=25)
# ts_provider_3 = FFmpegTimeStampProvider("path/to/video3.mp4", camera_id=3, fps=25)
#
# # è·å–æŸä¸€å¸§çš„æ—¶é—´æˆ³
# frame_id = 100
# timestamp_1 = ts_provider_1.get_timestamp(frame_id)  # è¿”å›ç»å¯¹æ—¶é—´å­—ç¬¦ä¸²
# # æ—¶é—´æˆ³ = start_datetime + frame_id / fps
# # ä¾‹å¦‚ï¼š2025-11-21 11:18:09.304 + 100/25ç§’ = 2025-11-21 11:18:13.304
#
# ============================================================================

# åˆ›å»ºå…¨å±€Configå®ä¾‹ï¼Œä»¥ä¾¿ç›´æ¥é€šè¿‡Config.FPSç­‰æ–¹å¼è®¿é—®
Config = _Config()