import os
import sys
import time
import multiprocessing
import copy
import json
from collections import defaultdict, deque
from statistics import mean, median
sys.path.append('/usr/local/lynxi/sdk/sdk-samples/python')

import numpy as np
import cv2
from ctypes import *
import ctypes
from dataclasses import dataclass
from typing import List, Tuple, Optional, Set, Dict


# --- æ€§èƒ½ç›‘è§†å™¨ç±» ---
import logging

logger = logging.getLogger(__name__)

class PerformanceMonitor:
    """ç®€åŒ–çš„æ€§èƒ½ç›‘è§†å™¨ - åªä¿ç•™åŸºæœ¬è®¡æ•°å’ŒFPSç»Ÿè®¡"""
    
    def __init__(self):
        self.counters = defaultdict(int)
        self.timers = {}
        self.start_time = time.time()
        self.last_report_time = time.time()
        self.report_interval = 10.0
        self.perf_data = defaultdict(lambda: {'total_ms': 0, 'count': 0})  # ğŸ”§ æ–°å¢ï¼šå­˜å‚¨è®¡æ—¶æ•°æ®
        
        logger.info("æ€§èƒ½ç›‘è§†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def start_timer(self, name: str):
        """å¼€å§‹è®¡æ—¶"""
        self.timers[name] = time.time()
    
    def end_timer(self, name: str) -> float:
        """ç»“æŸè®¡æ—¶å¹¶è¿”å›è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰"""
        if name not in self.timers:
            return 0.0
        elapsed = (time.time() - self.timers[name]) * 1000
        del self.timers[name]
        # ğŸ”§ æ–°å¢ï¼šä¿å­˜åˆ° perf_data
        self.perf_data[name]['total_ms'] = elapsed
        self.perf_data[name]['count'] += 1
        return elapsed
    
    def add_counter(self, name: str, value: int = 1):
        """å¢åŠ è®¡æ•°å™¨"""
        self.counters[name] += value
    
    def record_queue_stats(self, camera_id: int, queue_size: int, operation: str):
        """è®°å½•é˜Ÿåˆ—çŠ¶æ€ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        pass  # å¦‚æœéœ€è¦å¯ä»¥æ·»åŠ ç®€å•çš„æ—¥å¿—
    
    def record_fusion_stats(self, operation: str, duration_ms: float, details: dict = None):
        """è®°å½•èåˆç»Ÿè®¡ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        pass  # å¦‚æœéœ€è¦å¯ä»¥æ·»åŠ ç®€å•çš„æ—¥å¿—
    
    def get_performance_report(self) -> str:
        """ç”Ÿæˆç®€åŒ–çš„æ€§èƒ½æŠ¥å‘Š"""
        current_time = time.time()
        elapsed = current_time - self.last_report_time
        
        if elapsed < self.report_interval:
            return ""
        
        total_elapsed = current_time - self.start_time
        self.last_report_time = current_time
        
        # ç®€å•çš„FPSè®¡ç®—
        fps = self.counters.get('frames_processed', 0) / total_elapsed if total_elapsed > 0 else 0
        sync_fps = self.counters.get('frames_synchronized', 0) / total_elapsed if total_elapsed > 0 else 0
        
        report = []
        report.append(f"\n{'='*60}")
        report.append(f"ğŸ“Š æ€§èƒ½æŠ¥å‘Š (è¿è¡Œæ—¶é—´: {total_elapsed:.1f}s)")
        report.append(f"{'='*60}")
        report.append(f"å¤„ç†é€Ÿåº¦: {fps:.2f} FPS (åŒæ­¥: {sync_fps:.2f} FPS)")
        report.append(f"æ€»å¸§æ•°: {self.counters.get('frames_processed', 0)}")
        report.append(f"åŒæ­¥å¸§æ•°: {self.counters.get('frames_synchronized', 0)}")
        report.append(f"æ£€æµ‹æ•°: {self.counters.get('detections_processed', 0)}")
        report.append(f"BEVè½¬æ¢: {self.counters.get('bev_conversions', 0)}")
        report.append(f"MQTTå‘é€: {self.counters.get('mqtt_sends', 0)} (å¤±è´¥: {self.counters.get('mqtt_failures', 0)})")
        report.append(f"{'='*60}")
        
        return "\n".join(report)
    
    def reset_counters(self):
        """é‡ç½®è®¡æ•°å™¨"""
        self.counters.clear()
        self.start_time = time.time()
        self.last_report_time = time.time()
# --- é…ç½®ç±» (æŒ‰èŒè´£æ‹†åˆ†) ---

@dataclass
class ImageConfig:
    """å›¾åƒå’Œè§†é¢‘ç›¸å…³é…ç½®"""
    WIDTH: int = 1280
    HEIGHT: int = 720
    FPS: int = 25

@dataclass
class TrackingConfig:
    """ç›®æ ‡è·Ÿè¸ªç›¸å…³é…ç½®"""
    TRACK_THRESH: float = 0.3
    MATCH_THRESH: float = 0.6
    MIN_FRAMES_THRESHOLD: int = 10
    IOU_THRESHOLD: float = 0.5
    TOLERANCE_FRAMES: int = 60

@dataclass
class VehicleConfig:
    """è½¦è¾†ç±»åˆ«ç›¸å…³é…ç½®"""
    VEHICLE_CLASSES: List[str] = None
    EXCLUDE_CLASSES: List[str] = None
    SIMILAR_CLASSES: Dict[str, List[str]] = None
    
    def __post_init__(self):
        if self.VEHICLE_CLASSES is None:
            self.VEHICLE_CLASSES = [
                'mini_truck', 'truck', 'bus', 'van', 'car', 'ambulance',
                'fireEngine', 'schoolBus', 'tanker', 'muckTruck',
                'concreteTruck', 'policeCar'
            ]
        if self.EXCLUDE_CLASSES is None:
            self.EXCLUDE_CLASSES = ["person", "electric_vehicle", "bike", "tricycle", "engineer"]
        if self.SIMILAR_CLASSES is None:
            self.SIMILAR_CLASSES = {
                'mini_truck': ['truck', 'van', 'car'],
                'truck': ['mini_truck', 'van', 'car'],
                'van': ['mini_truck', 'truck', 'car'],
                'car': ['van', 'mini_truck', 'truck'],
                'bus': ['truck', 'van', 'car'],
            }


@dataclass
class FusionConfig:
    """è·¨æ‘„åƒå¤´èåˆç›¸å…³é…ç½®"""
    TIME_WINDOW: int = 80
    TEMPORAL_WINDOW_MAX: int = 225
    BASE_SPATIAL_THRESHOLD: float = 400.0
    
    # æŒ‰å¯¹é˜Ÿåˆ—èåˆé…ç½®
    ENABLE_SEQ_MATCHING: bool = True
    RESERVATION_TTL_FRAMES: int = 60
    MAX_RETENTION_FRAMES: int = 200
    TIME_WINDOW_STRICT: int = 30
    TIME_WINDOW_FLEXIBLE: int = 60
    
    # ğŸ”§ èåˆæ—¶é—´çª—å£
    FUSION_TIME_WINDOW: int = 60
    
    # C2 å‡ºå£åŒºåŸŸ (BEVåæ ‡)
    C2_EXIT_REGION_C3: np.ndarray = None
    C2_EXIT_REGION_C1: np.ndarray = None
    
    # é›·è§†èåˆåŒºåŸŸ (åƒç´ åæ ‡) - ç”¨äºæ ‡è®°å¯è¿›è¡Œé›·è§†èåˆçš„åŒºåŸŸ
    RADAR_VISION_FUSION_AREAS: Dict[int, np.ndarray] = None
    
    
    def __post_init__(self):
        if self.C2_EXIT_REGION_C3 is None:
            self.C2_EXIT_REGION_C3 = np.array(
                [[1022, 654], [1092, 605], [1082, 589], [1011, 642]], dtype=np.int32
            )
        if self.C2_EXIT_REGION_C1 is None:
            self.C2_EXIT_REGION_C1 = np.array(
                [[1022, 654], [1011, 642], [871, 735], [884, 757]], dtype=np.int32
            )
        if self.RADAR_VISION_FUSION_AREAS is None:
            self.RADAR_VISION_FUSION_AREAS = {
                1: np.array([[110, 429], [0, 536], [0, 720], [1280, 720], [1280, 458]], dtype=np.int32),
                2: np.array([[0, 720], [1280, 720], [1280, 418], [109, 432]], dtype=np.int32),
                3: np.array([[328, 472], [186, 720], [1033, 720], [985, 468]], dtype=np.int32),
            }

@dataclass
class TimestampConfig:
    """æ—¶é—´æˆ³ç›¸å…³é…ç½®"""
    CAMERA_START_DATETIMES: Dict[int, str] = None
    
    def __post_init__(self):
        if self.CAMERA_START_DATETIMES is None:
            self.CAMERA_START_DATETIMES = {
                1: "2025-11-21 11:59:12.135",
                2: "2025-11-21 11:59:12.150",
                3: "2025-11-21 11:59:12.143",
            }

class _Config:
    """ç»Ÿä¸€çš„é…ç½®ç®¡ç†ç±» - ä½¿ç”¨ç»„åˆæ¨¡å¼"""
    def __init__(self):
        self.image = ImageConfig()
        self.tracking = TrackingConfig()
        self.vehicle = VehicleConfig()
        self.fusion = FusionConfig()
        self.timestamp = TimestampConfig()
    
    # ä¸ºäº†å‘åå…¼å®¹ï¼Œæä¾›å±æ€§è®¿é—®
    @property
    def IMAGE_WIDTH(self): return self.image.WIDTH
    @property
    def IMAGE_HEIGHT(self): return self.image.HEIGHT
    @property
    def FPS(self): return self.image.FPS
    @property
    def TRACK_THRESH(self): return self.tracking.TRACK_THRESH
    @property
    def MATCH_THRESH(self): return self.tracking.MATCH_THRESH
    @property
    def MIN_FRAMES_THRESHOLD(self): return self.tracking.MIN_FRAMES_THRESHOLD
    @property
    def IOU_THRESHOLD(self): return self.tracking.IOU_THRESHOLD
    @property
    def TOLERANCE_FRAMES(self): return self.tracking.TOLERANCE_FRAMES
    @property
    def VEHICLE_CLASSES(self): return self.vehicle.VEHICLE_CLASSES
    @property
    def EXCLUDE_CLASSES(self): return self.vehicle.EXCLUDE_CLASSES
    @property
    def SIMILAR_CLASSES(self): return self.vehicle.SIMILAR_CLASSES
    @property
    def TIME_WINDOW(self): return self.fusion.TIME_WINDOW
    @property
    def TEMPORAL_WINDOW_MAX(self): return self.fusion.TEMPORAL_WINDOW_MAX
    @property
    def BASE_SPATIAL_THRESHOLD(self): return self.fusion.BASE_SPATIAL_THRESHOLD
    @property
    def ENABLE_SEQ_MATCHING(self): return self.fusion.ENABLE_SEQ_MATCHING
    @property
    def RESERVATION_TTL_FRAMES(self): return self.fusion.RESERVATION_TTL_FRAMES
    @property
    def MAX_RETENTION_FRAMES(self): return self.fusion.MAX_RETENTION_FRAMES
    @property
    def TIME_WINDOW_STRICT(self): return self.fusion.TIME_WINDOW_STRICT
    @property
    def TIME_WINDOW_FLEXIBLE(self): return self.fusion.TIME_WINDOW_FLEXIBLE
    @property
    def FUSION_TIME_WINDOW(self): return self.fusion.FUSION_TIME_WINDOW
    @property
    def PIXEL_BOTTOM_THRESHOLD(self): return self.fusion.PIXEL_BOTTOM_THRESHOLD
    @property
    def PIXEL_TOP_THRESHOLD(self): return self.fusion.PIXEL_TOP_THRESHOLD
    @property
    def C2_EXIT_REGION_C3(self): return self.fusion.C2_EXIT_REGION_C3
    @property
    def C2_EXIT_REGION_C1(self): return self.fusion.C2_EXIT_REGION_C1
    @property
    def RADAR_VISION_FUSION_AREAS(self): return self.fusion.RADAR_VISION_FUSION_AREAS
    @property
    def CAMERA_START_DATETIMES(self): return self.timestamp.CAMERA_START_DATETIMES

# çŸ©é˜µå’ŒåŒºåŸŸé…ç½®
CAMERA_MATRICES = {
    1: np.array([
        [3.57185777, -95.12052479, 4179.24844873],
        [3.46221359, -30.18092945, -4782.56623337],
        [0.00086667, -0.07779328, 1.00000000]
    ], dtype=np.float64),
    2: np.array([
        [-3.14205205, -15.41287574, -466.38259912],
        [-3.41382642, -24.02931190, 3191.87948399],
        [-0.00259235, -0.02359469, 1.00000000]
    ], dtype=np.float64),
    3: np.array([
        [2.30699835, -25.77644591, -1583.82133879],
        [-0.42448874, -13.71274357, -988.28445704],
        [0.00112695, -0.03632265, 1.00000000]
    ], dtype=np.float64),
}

# ğŸ”§ æ–°å¢ï¼šBEVåˆ°ä¸–ç•Œç±³åˆ¶åæ ‡çš„å˜æ¢çŸ©é˜µ
BEV_TO_WORLD_METER_MATRIX = np.array([
    [1.32977514e-01, -1.04276598e-04, -1.50540001e+02],
    [1.45689395e-03, -1.33712569e-01, 7.61259809e+01],
    [-1.97872483e-06, -2.12579392e-05, 1.00000000e+00]
], dtype=np.float64)

# ğŸ”§ æ–°å¢ï¼šBEVåˆ°åœ°ç†åæ ‡çš„å˜æ¢çŸ©é˜µï¼ˆä½¿ç”¨BEV_TO_WORLD_METER_MATRIXä½œä¸ºåŸºç¡€ï¼‰
BEV_TO_GEO_MATRIX = BEV_TO_WORLD_METER_MATRIX

# ğŸ”§ æ–°å¢ï¼šåœ°ç†åæ ‡åŸç‚¹ (å‚è€ƒç‚¹)
# è¿™æ˜¯ calculate_geo.py ä¸­ä½¿ç”¨çš„ç¬¬ä¸€ä¸ªç‚¹åæ ‡
GEO_ORIGIN_LON = 113.584439426
GEO_ORIGIN_LAT = 23.530769118

# ğŸ”§ æ–°å¢ï¼šåœ°çƒç›¸å…³å¸¸æ•°ç”¨äºç»çº¬åº¦è½¬æ¢
import math
EARTH_RADIUS = 6378137.0  # åœ°çƒåŠå¾„ (ç±³)
METERS_PER_DEG_LAT = (math.pi / 180.0) * EARTH_RADIUS
METERS_PER_DEG_LON = (math.pi / 180.0) * EARTH_RADIUS * math.cos(math.radians(GEO_ORIGIN_LAT))

PUBLIC_AREA_BEV = np.array([[1075, 606], [1066, 575], [850, 747], [877, 760]], dtype=np.int32)

# YOLOv5 ç±»åˆ«åç§°
NAMES = [
    'mini_truck','truck','bus','van','car','person','bike','electric_vehicle',
    'tricycle','engineer','ambulance','fireEngine','schoolBus','tanker','muckTruck',
    'concreteTruck','policeCar'
]

# --- å‡ ä½•å’Œæ£€æµ‹å·¥å…·ç±» ---
class GeometryUtils:
    @staticmethod
    def project_pixel_to_bev(H: np.ndarray, u: float, v: float) -> Optional[Tuple[float, float]]:
        """å•ä¸ªåƒç´ åˆ°BEVçš„è½¬æ¢"""
        p = np.array([u, v, 1.0])
        q = H @ p
        if abs(q[2]) < 1e-8: return None
        x, y = q[0] / q[2], q[1] / q[2]
        return (x, y)


    @staticmethod
    def bev_to_geo(x_bev: float, y_bev: float) -> Optional[Tuple[float, float]]:
        """BEVåƒç´  -> ä¸–ç•Œç±³åˆ¶åæ ‡ -> åœ°ç†åæ ‡ (ç»çº¬åº¦)"""
        try:
            # æ­¥éª¤1: BEVåƒç´  -> ä¸–ç•Œç±³åˆ¶åæ ‡
            p = np.array([x_bev, y_bev, 1.0])
            q = BEV_TO_GEO_MATRIX @ p
            q /= q[2]
            x_meters = q[0]  # ç›¸å¯¹äºåŸç‚¹çš„Xåç§» (ç±³)
            y_meters = q[1]  # ç›¸å¯¹äºåŸç‚¹çš„Yåç§» (ç±³)
            
            # æ­¥éª¤2: ä¸–ç•Œç±³åˆ¶åæ ‡ -> åœ°ç†åæ ‡ (ç»çº¬åº¦)
            # (ç±³ / æ¯åº¦ç±³æ•°) + åŸç‚¹åº¦æ•°
            lon = (x_meters / METERS_PER_DEG_LON) + GEO_ORIGIN_LON
            lat = (y_meters / METERS_PER_DEG_LAT) + GEO_ORIGIN_LAT
            
            return lon, lat
        except: 
            return None


    @staticmethod
    def calculate_iou(box1: List[float], box2: List[float]) -> float:
        x1_1, y1_1, x2_1, y2_1 = box1
        x1_2, y1_2, x2_2, y2_2 = box2
        x1_i, y1_i = max(x1_1, x1_2), max(y1_1, y1_2)
        x2_i, y2_i = min(x2_1, x2_2), min(y2_1, y2_2)
        if x2_i <= x1_i or y2_i <= y1_i: return 0.0
        intersection = (x2_i - x1_i) * (y2_i - y1_i)
        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
        union = area1 + area2 - intersection
        return intersection / union if union > 0 else 0.0

    @staticmethod
    def is_in_public_area(bev_point: Tuple[float, float]) -> bool:
        return cv2.pointPolygonTest(PUBLIC_AREA_BEV, bev_point, False) >= 0
    
    @staticmethod
    def is_in_radar_vision_fusion_area(pixel_point: Tuple[int, int], camera_id: int) -> bool:
        """æ£€æŸ¥åƒç´ ç‚¹æ˜¯å¦åœ¨è¯¥æ‘„åƒå¤´çš„é›·è§†èåˆåŒºåŸŸå†…"""
        # è·å–Configå®ä¾‹çš„èåˆåŒºåŸŸé…ç½®
        fusion_areas = Config.RADAR_VISION_FUSION_AREAS
        if not fusion_areas or camera_id not in fusion_areas:
            return False
        fusion_area = fusion_areas[camera_id]
        return cv2.pointPolygonTest(fusion_area, pixel_point, False) >= 0

class DetectionUtils:
    @staticmethod
    def is_class_compatible(class1: str, class2: str) -> bool:
        if class1 == class2: return True
        return (class1 in Config.SIMILAR_CLASSES and 
                class2 in Config.SIMILAR_CLASSES[class1])

    @staticmethod
    def non_max_suppression(detections: List[dict], 
                          iou_threshold: float = None) -> List[dict]:
        if iou_threshold is None:
            iou_threshold = Config.IOU_THRESHOLD
        if not detections: return detections
        detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)
        keep = []
        for det in detections:
            should_keep = True
            for kept_det in keep:
                if DetectionUtils.is_class_compatible(det['class'], kept_det['class']):
                    iou = GeometryUtils.calculate_iou(det['box'], kept_det['box'])
                    if iou > iou_threshold:
                        should_keep = False; break
            if should_keep: keep.append(det)
        return keep

    @staticmethod
    def is_turn_left(trajectory: List[Tuple[int, int]]) -> bool:
        if len(trajectory) < 2: return False
        start = np.array(trajectory[0])
        # ç®€åŒ–å·¦è½¬åˆ¤æ–­ï¼šå¦‚æœèµ·å§‹ç‚¹åœ¨å›¾åƒåº•éƒ¨ï¼Œåˆ™å¯èƒ½ä¸ºå·¦è½¬
        return start[1] >= Config.IMAGE_HEIGHT * 0.7 
        
# --- å¹³æ»‘æ»¤æ³¢å™¨ç±» ---
class SmoothingFilter:
    """
    å¯¹ç›®æ ‡çš„BEVåæ ‡è¿›è¡Œå¹³æ»‘å¤„ç†ã€‚
    """
    def __init__(self, history_len: int = 10, alpha: float = 0.5):
        # å­˜å‚¨æ¯ä¸ªç›®æ ‡ (track_id) çš„BEVåæ ‡å†å²
        self.bev_history = defaultdict(lambda: deque(maxlen=history_len))
        # æŒ‡æ•°å¹³æ»‘çš„æƒé‡å› å­ (0 < alpha < 1)ï¼Œæ•°å€¼è¶Šå°è¶Šå¹³æ»‘
        self.alpha = alpha
        
    def _sliding_average(self, track_id: int, current_bev: Tuple[float, float]) -> Tuple[float, float]:
        """æ»‘åŠ¨å¹³å‡å¹³æ»‘ (Moving Average)"""
        self.bev_history[track_id].append(current_bev)
        
        history = self.bev_history[track_id]
        if len(history) < 2:
            return current_bev
            
        # è®¡ç®—å†å²ç‚¹çš„å¹³å‡å€¼
        avg_x = sum(p[0] for p in history) / len(history)
        avg_y = sum(p[1] for p in history) / len(history)
        
        return (avg_x, avg_y)

    def _exponential_smoothing(self, track_id: int, current_bev: Tuple[float, float]) -> Tuple[float, float]:
        """æŒ‡æ•°å¹³æ»‘ (Exponential Smoothing)"""
        history_deque = self.bev_history[track_id]
        
        if not history_deque:
            # ç¬¬ä¸€æ¬¡æµ‹é‡ï¼Œç›´æ¥ä½¿ç”¨å½“å‰å€¼ä½œä¸ºå¹³æ»‘å€¼
            smoothed_bev = current_bev
        else:
            last_smoothed_bev = history_deque[-1]
            
            # P'_t = alpha * P_t + (1 - alpha) * P'_{t-1}
            smoothed_x = self.alpha * current_bev[0] + (1 - self.alpha) * last_smoothed_bev[0]
            smoothed_y = self.alpha * current_bev[1] + (1 - self.alpha) * last_smoothed_bev[1]
            smoothed_bev = (smoothed_x, smoothed_y)

        history_deque.append(smoothed_bev)
        return smoothed_bev
    
    def apply_smoothing(self, track_id: int, current_bev: Tuple[float, float], method: str = 'exponential') -> Tuple[float, float]:
        """åº”ç”¨å¹³æ»‘ç®—æ³•å¹¶è¿”å›å¹³æ»‘åçš„BEVåæ ‡"""
        if method == 'sliding':
            return self._sliding_average(track_id, current_bev)
        else: # é»˜è®¤ä¸ºæŒ‡æ•°å¹³æ»‘ï¼Œé€šå¸¸æ•ˆæœæ›´å¥½
            return self._exponential_smoothing(track_id, current_bev)

    def remove_track(self, track_id: int):
        """ç§»é™¤ä¸å†æ´»è·ƒçš„ç›®æ ‡çš„å†å²è®°å½•"""
        self.bev_history.pop(track_id, None)


# ============================================================================
# ğŸ”§ æ—¶é—´æˆ³æä¾›å™¨ä½¿ç”¨ç¤ºä¾‹
# ============================================================================
# 
# åœ¨ä½ çš„ä¸»ç¨‹åºä¸­ï¼Œåˆå§‹åŒ–æ—¶é—´æˆ³æä¾›å™¨ä¹‹å‰ï¼Œå…ˆè®¾ç½®æ‘„åƒå¤´çš„èµ·å§‹æ—¶é—´ï¼š
#
# ç¤ºä¾‹ä»£ç ï¼š
# --------
# from ffmpeg_timestamp_sync import FFmpegTimeStampProvider
#
# # æ–¹æ³•1ï¼šæ‰¹é‡è®¾ç½®æ‰€æœ‰æ‘„åƒå¤´çš„èµ·å§‹æ—¶é—´
# FFmpegTimeStampProvider.set_all_camera_start_datetimes(Config.CAMERA_START_DATETIMES)
#
# # æ–¹æ³•2ï¼šå•ä¸ªè®¾ç½®ï¼ˆå¯é€‰ï¼‰
# # FFmpegTimeStampProvider.set_camera_start_datetime(1, "2025-11-21 11:18:09.304")
# # FFmpegTimeStampProvider.set_camera_start_datetime(2, "2025-11-21 11:18:09.500")
# # FFmpegTimeStampProvider.set_camera_start_datetime(3, "2025-11-21 11:18:10.000")
#
# # ç„¶ååˆ›å»ºæ—¶é—´æˆ³æä¾›å™¨å®ä¾‹
# ts_provider_1 = FFmpegTimeStampProvider("path/to/video1.mp4", camera_id=1, fps=25)
# ts_provider_2 = FFmpegTimeStampProvider("path/to/video2.mp4", camera_id=2, fps=25)
# ts_provider_3 = FFmpegTimeStampProvider("path/to/video3.mp4", camera_id=3, fps=25)
#
# # è·å–æŸä¸€å¸§çš„æ—¶é—´æˆ³
# frame_id = 100
# timestamp_1 = ts_provider_1.get_timestamp(frame_id)  # è¿”å›ç»å¯¹æ—¶é—´å­—ç¬¦ä¸²
# # æ—¶é—´æˆ³ = start_datetime + frame_id / fps
# # ä¾‹å¦‚ï¼š2025-11-21 11:18:09.304 + 100/25ç§’ = 2025-11-21 11:18:13.304
#
# ============================================================================

# åˆ›å»ºå…¨å±€Configå®ä¾‹ï¼Œä»¥ä¾¿ç›´æ¥é€šè¿‡Config.FPSç­‰æ–¹å¼è®¿é—®
Config = _Config()

# --- æ£€æµ‹å’Œè·Ÿè¸ªè¾…åŠ©å‡½æ•° ---
def filter_by_detect_areas(detections: List[dict], areas: List[np.ndarray]) -> List[dict]:
    """æ ¹æ®æ£€æµ‹åŒºåŸŸè¿‡æ»¤æ£€æµ‹ç»“æœ"""
    filtered_detections = []
    for detection in detections:
        # ä½¿ç”¨è¾¹ç•Œæ¡†çš„åº•éƒ¨ä¸­å¿ƒç‚¹ä½œä¸ºåˆ¤æ–­ç‚¹
        x1, y1, x2, y2 = detection['box']
        center_x, center_y = int((x1 + x2) / 2), int(y2) 
        in_detect_area = any(cv2.pointPolygonTest(area, (center_x, center_y), False) >= 0 
                           for area in areas)
        if in_detect_area:
            filtered_detections.append(detection)
    return filtered_detections


def batch_prepare_tracker_input(nms_detections: List[dict]) -> Tuple[np.ndarray, Dict[str, str]]:
    """
    æ‰¹é‡å‡†å¤‡è·Ÿè¸ªå™¨è¾“å…¥ï¼Œä¼˜åŒ–æ€§èƒ½ - ä½¿ç”¨numpyé¿å…torchä¾èµ–
    åŒæ—¶è¿”å›æ£€æµ‹æ¡†åˆ°ç±»åˆ«çš„æ˜ å°„å­—å…¸
    """
    if not nms_detections:
        return np.empty((0, 5), dtype=np.float32), {}
    
    # æ‰¹é‡æå–æ•°æ®ï¼Œé¿å…å¾ªç¯
    # BYTETracker æœŸæœ›çš„æ ¼å¼: [x1, y1, x2, y2, score]
    boxes_scores = np.array([[d['box'][0], d['box'][1], d['box'][2], d['box'][3], d['confidence']] 
                              for d in nms_detections], dtype=np.float32)
    
    # åˆ›å»ºæ˜ å°„å­—å…¸ï¼škeyä¸ºboxçš„å­—ç¬¦ä¸²è¡¨ç¤ºï¼Œvalueä¸ºç±»åˆ«åç§°
    # è¿™æ ·å¯ä»¥é€šè¿‡boxåæ ‡å¿«é€ŸæŸ¥æ‰¾å¯¹åº”çš„ç±»åˆ«
    box_to_class = {}
    for i, det in enumerate(nms_detections):
        box_key = f"{det['box'][0]:.1f}_{det['box'][1]:.1f}_{det['box'][2]:.1f}_{det['box'][3]:.1f}"
        box_to_class[box_key] = det['class']
    
    # è·Ÿè¸ªå™¨åªéœ€è¦å‰5åˆ—ï¼š[x1, y1, x2, y2, score]
    tracker_input_array = boxes_scores.astype(np.float32)
    return tracker_input_array, box_to_class


def batch_convert_track_results(tracked_objects: List, result: dict, camera_id: int, current_frame: int, 
                               original_detections: List[dict] = None, box_to_class: Dict[str, str] = None) -> List[dict]:
    """
    æ‰¹é‡è½¬æ¢è·Ÿè¸ªç»“æœï¼Œä¼˜åŒ–æ€§èƒ½å¹¶ä¿ç•™åŸå§‹ç±»åˆ«ä¿¡æ¯
    box_to_class: æ£€æµ‹æ¡†åˆ°ç±»åˆ«çš„æ˜ å°„å­—å…¸
    """
    from config.region_config import get_lane_for_point
    
    tracked_detections = []
    
    # æ·»åŠ è°ƒè¯•ä¿¡æ¯
    if current_frame % 100 == 0 and len(tracked_objects) > 0:
        logger.debug(f"C{camera_id} Frame {current_frame}: {len(tracked_objects)} tracked objects")
    
    for track in tracked_objects:
        # é«˜æ•ˆè½¬æ¢tlwhåˆ°tlbr
        tlwh = track.tlwh
        tlbr = [tlwh[0], tlwh[1], tlwh[0] + tlwh[2], tlwh[1] + tlwh[3]]
        
        # å°è¯•ä»box_to_classæ˜ å°„ä¸­è·å–ç±»åˆ«ä¿¡æ¯ï¼ˆæœ€å‡†ç¡®çš„æ–¹æ³•ï¼‰
        class_name = 'car'  # é»˜è®¤å€¼
        
        if box_to_class:
            # å°è¯•é€šè¿‡IoUåŒ¹é…æ‰¾åˆ°å¯¹åº”çš„åŸå§‹æ£€æµ‹
            best_iou = 0
            best_class = None
            best_box_key = None
            
            for box_key, class_str in box_to_class.items():
                # è§£æbox_key
                coords = box_key.split('_')
                if len(coords) == 4:
                    try:
                        orig_box = [float(c) for c in coords]
                        iou = GeometryUtils.calculate_iou(tlbr, orig_box)
                        if iou > best_iou and iou > 0.1:  # é™ä½IoUé˜ˆå€¼
                            best_iou = iou
                            best_class = class_str
                            best_box_key = box_key
                    except:
                        continue
            
            if best_class:
                class_name = best_class
                if box_to_class and best_box_key:
                    # åˆ é™¤å·²ä½¿ç”¨çš„æ˜ å°„ï¼Œé¿å…é‡å¤ä½¿ç”¨
                    del box_to_class[best_box_key]
            else:
                # å¦‚æœIoUåŒ¹é…å¤±è´¥ï¼Œå°è¯•é€šè¿‡è·ç¦»åŒ¹é…
                min_distance = float('inf')
                best_class_dist = None
                
                for box_key, class_str in box_to_class.items():
                    coords = box_key.split('_')
                    if len(coords) == 4:
                        try:
                            orig_box = [float(c) for c in coords]
                            orig_center = [(orig_box[0] + orig_box[2]) / 2, (orig_box[1] + orig_box[3]) / 2]
                            track_center = [(tlbr[0] + tlbr[2]) / 2, (tlbr[1] + tlbr[3]) / 2]
                            distance = ((orig_center[0] - track_center[0]) ** 2 + 
                                       (orig_center[1] - track_center[1]) ** 2) ** 0.5
                            
                            if distance < min_distance and distance < 100:  # 100åƒç´ å†…çš„æœ€è¿‘åŒ¹é…
                                min_distance = distance
                                best_class_dist = class_str
                        except:
                            continue
                
                if best_class_dist:
                    class_name = best_class_dist
        
        elif original_detections:
            # å¤‡é€‰æ–¹æ¡ˆï¼šä½¿ç”¨åŸå§‹æ£€æµ‹åˆ—è¡¨
            best_iou = 0
            best_match = None
            for orig_det in original_detections:
                iou = GeometryUtils.calculate_iou(tlbr, orig_det['box'])
                if iou > best_iou and iou > 0.1:
                    best_iou = iou
                    best_match = orig_det
            
            if best_match:
                class_name = best_match['class']
            else:
                # è·ç¦»åŒ¹é…
                min_distance = float('inf')
                for orig_det in original_detections:
                    orig_center = [(orig_det['box'][0] + orig_det['box'][2]) / 2, 
                                  (orig_det['box'][1] + orig_det['box'][3]) / 2]
                    track_center = [(tlbr[0] + tlbr[2]) / 2, (tlbr[1] + tlbr[3]) / 2]
                    distance = ((orig_center[0] - track_center[0]) ** 2 + 
                               (orig_center[1] - track_center[1]) ** 2) ** 0.5
                    
                    if distance < min_distance and distance < 100:
                        min_distance = distance
                        class_name = orig_det['class']
        
        # è®¡ç®—ç›®æ ‡åº•éƒ¨ä¸­å¿ƒç‚¹ï¼ˆç”¨äºèåˆåŒºåŸŸåˆ¤æ–­ï¼‰
        center_x = int((tlbr[0] + tlbr[2]) / 2)
        center_y = int(tlbr[3])
        pixel_point = (center_x, center_y)
        
        # åˆ¤æ–­è½¦é“æ‰€å±
        lane = get_lane_for_point(camera_id, center_x, center_y)
        
        # æ£€æŸ¥æ˜¯å¦åœ¨é›·è§†èåˆåŒºåŸŸå†…
        in_fusion_area = GeometryUtils.is_in_radar_vision_fusion_area(pixel_point, camera_id)
        
        detection = {
            'box': tlbr,
            'confidence': track.score,
            'class': class_name,  # ä¿ç•™åŸå§‹ç±»åˆ«ä¿¡æ¯
            'track_id': track.track_id,
            'local_id': track.track_id,
            'center_point': [(tlbr[0] + tlbr[2]) / 2, (tlbr[1] + tlbr[3]) / 2],
            'timestamp': result.get('timestamp', time.time()),
            'camera_id': camera_id,
            'lane': lane,  # æ–°å¢ï¼šè½¦é“ä¿¡æ¯
            'in_fusion_area': in_fusion_area  # æ–°å¢ï¼šæ ‡è®°æ˜¯å¦åœ¨èåˆåŒºåŸŸå†…
        }
        tracked_detections.append(detection)
    
    return tracked_detections