#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SDKç‰ˆå¤šæ‘„åƒå¤´èåˆç³»ç»Ÿ - é‡æ„ç‰ˆ
èŒè´£åˆ†ç¦»: 
1. å­è¿›ç¨‹ (yolov5_SDK): ä»…è´Ÿè´£è§†é¢‘è¯»å–ã€SDKæ¨ç†ã€ç»“æœå…¥é˜Ÿåˆ— (ä½¿ç”¨ SDKinfer_ffmpeg.py)
2. ä¸»è¿›ç¨‹ (main): è´Ÿè´£è·Ÿè¸ª(BYTETracker)ã€åŒºåŸŸè¿‡æ»¤ã€è·¨æ‘„åƒå¤´èåˆã€å¸§åŒæ­¥ 
"""

import os
import sys
import time
import multiprocessing
import copy
import json
import signal
import logging
import queue
from collections import defaultdict, deque
from statistics import mean, median
sys.path.append('/usr/local/lynxi/sdk/sdk-samples/python')

# é…ç½®logging - åªè¾“å‡ºåˆ°æ–‡ä»¶ï¼Œä¸è¾“å‡ºåˆ°ç»ˆç«¯
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('fusion_system.log', mode='w', encoding='utf-8')  # mode='w' æ¯æ¬¡è¿è¡Œæ—¶æ¸…ç©ºæ—¥å¿—
    ]
)
logger = logging.getLogger(__name__)

import numpy as np
import cv2
from ctypes import *
import ctypes
from dataclasses import dataclass
from typing import List, Tuple, Optional, Set, Dict

# å¯¼å…¥SDKç›¸å…³æ¨¡å—
import pycommon.common as common
import pylynchipsdk as sdk
from pycommon.infer_process import *
from pycommon.callback_data_struct import *
from pycommon.dump_json import *
from ByteTrack.optimized_byte_tracker import OptimizedBYTETracker as BYTETracker

# å¯¼å…¥RTSPå’ŒMQTTç›¸å…³æ¨¡å— (æ–°å¢)
try:
    from rtsp_reader import RTSPStreamReader
    from mqtt_publisher import MqttPublisher  
    from config_reader import ConfigReader
    RTSP_MQTT_AVAILABLE = True
except ImportError as e:
    logger.warning(f"æ— æ³•å¯¼å…¥RTSP/MQTTæ¨¡å—: {e}, å°†ä½¿ç”¨æœ¬åœ°è§†é¢‘æ¨¡å¼")
    RTSP_MQTT_AVAILABLE = False

# ğŸ”§ ç§»é™¤FFmpegç›¸å…³å¯¼å…¥ï¼Œæ”¹ç”¨ç›´æ¥è®¡ç®—æ—¶é—´æˆ³
# from Timestamp_sync import FFmpegTimeStampProvider, FFmpegTimestampFrameSynchronizer
from Basic import Config, DetectionUtils, GeometryUtils, PerformanceMonitor
from TargetTrack import TargetBuffer
from Fusion import CrossCameraFusion
from RadarVisionFusion import RadarVisionFusionProcessor, RadarDataLoader, OutputObject
from CameraManager import CameraManager

# åˆ›å»ºå…±äº«å¸ƒå°”å€¼ç”¨äºåœæ­¢è¿è¡Œçº¿ç¨‹
cancel_flag = multiprocessing.Value('b', False)
# --- è¾…åŠ©å‡½æ•° (ä»SDKinfer.pyç§»è¿‡æ¥) ---

def cancel_process(signum, frame):
    """å–æ¶ˆå¤„ç†ä¿¡å·"""
    global cancel_flag
    cancel_flag.value = True
    logger.info("æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...")

def filter_by_detect_areas(detections: List[dict], areas: List[np.ndarray]) -> List[dict]:
    """æ ¹æ®æ£€æµ‹åŒºåŸŸè¿‡æ»¤æ£€æµ‹ç»“æœ"""
    filtered_detections = []
    for detection in detections:
        # ä½¿ç”¨è¾¹ç•Œæ¡†çš„åº•éƒ¨ä¸­å¿ƒç‚¹ä½œä¸ºåˆ¤æ–­ç‚¹
        x1, y1, x2, y2 = detection['box']
        center_x, center_y = int((x1 + x2) / 2), int(y2) 
        in_detect_area = any(cv2.pointPolygonTest(area, (center_x, center_y), False) >= 0 
                           for area in areas)
        if in_detect_area:
            filtered_detections.append(detection)
    return filtered_detections

def batch_prepare_tracker_input(nms_detections: List[dict]) -> Tuple[np.ndarray, Dict[str, str]]:
    """
    æ‰¹é‡å‡†å¤‡è·Ÿè¸ªå™¨è¾“å…¥ï¼Œä¼˜åŒ–æ€§èƒ½ - ä½¿ç”¨numpyé¿å…torchä¾èµ–
    åŒæ—¶è¿”å›æ£€æµ‹æ¡†åˆ°ç±»åˆ«çš„æ˜ å°„å­—å…¸
    """
    if not nms_detections:
        return np.empty((0, 5), dtype=np.float32), {}
    
    # æ‰¹é‡æå–æ•°æ®ï¼Œé¿å…å¾ªç¯
    # BYTETracker æœŸæœ›çš„æ ¼å¼: [x1, y1, x2, y2, score]
    boxes_scores = np.array([[d['box'][0], d['box'][1], d['box'][2], d['box'][3], d['confidence']] 
                              for d in nms_detections], dtype=np.float32)
    
    # åˆ›å»ºæ˜ å°„å­—å…¸ï¼škeyä¸ºboxçš„å­—ç¬¦ä¸²è¡¨ç¤ºï¼Œvalueä¸ºç±»åˆ«åç§°
    # è¿™æ ·å¯ä»¥é€šè¿‡boxåæ ‡å¿«é€ŸæŸ¥æ‰¾å¯¹åº”çš„ç±»åˆ«
    box_to_class = {}
    for i, det in enumerate(nms_detections):
        box_key = f"{det['box'][0]:.1f}_{det['box'][1]:.1f}_{det['box'][2]:.1f}_{det['box'][3]:.1f}"
        box_to_class[box_key] = det['class']
    
    # è·Ÿè¸ªå™¨åªéœ€è¦å‰5åˆ—ï¼š[x1, y1, x2, y2, score]
    tracker_input_array = boxes_scores.astype(np.float32)
    return tracker_input_array, box_to_class

def batch_convert_track_results(tracked_objects: List, result: dict, camera_id: int, current_frame: int, 
                               original_detections: List[dict] = None, box_to_class: Dict[str, str] = None) -> List[dict]:
    """
    æ‰¹é‡è½¬æ¢è·Ÿè¸ªç»“æœï¼Œä¼˜åŒ–æ€§èƒ½å¹¶ä¿ç•™åŸå§‹ç±»åˆ«ä¿¡æ¯
    box_to_class: æ£€æµ‹æ¡†åˆ°ç±»åˆ«çš„æ˜ å°„å­—å…¸
    """
    tracked_detections = []
    
    # æ·»åŠ è°ƒè¯•ä¿¡æ¯
    if current_frame % 100 == 0 and len(tracked_objects) > 0:
        logger.debug(f"C{camera_id} Frame {current_frame}: {len(tracked_objects)} tracked objects")
    
    for track in tracked_objects:
        # é«˜æ•ˆè½¬æ¢tlwhåˆ°tlbr
        tlwh = track.tlwh
        tlbr = [tlwh[0], tlwh[1], tlwh[0] + tlwh[2], tlwh[1] + tlwh[3]]
        
        # å°è¯•ä»box_to_classæ˜ å°„ä¸­è·å–ç±»åˆ«ä¿¡æ¯ï¼ˆæœ€å‡†ç¡®çš„æ–¹æ³•ï¼‰
        class_name = 'car'  # é»˜è®¤å€¼
        
        if box_to_class:
            # å°è¯•é€šè¿‡IoUåŒ¹é…æ‰¾åˆ°å¯¹åº”çš„åŸå§‹æ£€æµ‹
            best_iou = 0
            best_class = None
            best_box_key = None
            
            for box_key, class_str in box_to_class.items():
                # è§£æbox_key
                coords = box_key.split('_')
                if len(coords) == 4:
                    try:
                        orig_box = [float(c) for c in coords]
                        iou = GeometryUtils.calculate_iou(tlbr, orig_box)
                        if iou > best_iou and iou > 0.1:  # é™ä½IoUé˜ˆå€¼
                            best_iou = iou
                            best_class = class_str
                            best_box_key = box_key
                    except:
                        continue
            
            if best_class:
                class_name = best_class
                if box_to_class and best_box_key:
                    # åˆ é™¤å·²ä½¿ç”¨çš„æ˜ å°„ï¼Œé¿å…é‡å¤ä½¿ç”¨
                    del box_to_class[best_box_key]
            else:
                # å¦‚æœIoUåŒ¹é…å¤±è´¥ï¼Œå°è¯•é€šè¿‡è·ç¦»åŒ¹é…
                min_distance = float('inf')
                best_class_dist = None
                
                for box_key, class_str in box_to_class.items():
                    coords = box_key.split('_')
                    if len(coords) == 4:
                        try:
                            orig_box = [float(c) for c in coords]
                            orig_center = [(orig_box[0] + orig_box[2]) / 2, (orig_box[1] + orig_box[3]) / 2]
                            track_center = [(tlbr[0] + tlbr[2]) / 2, (tlbr[1] + tlbr[3]) / 2]
                            distance = ((orig_center[0] - track_center[0]) ** 2 + 
                                       (orig_center[1] - track_center[1]) ** 2) ** 0.5
                            
                            if distance < min_distance and distance < 100:  # 100åƒç´ å†…çš„æœ€è¿‘åŒ¹é…
                                min_distance = distance
                                best_class_dist = class_str
                        except:
                            continue
                
                if best_class_dist:
                    class_name = best_class_dist
        
        elif original_detections:
            # å¤‡é€‰æ–¹æ¡ˆï¼šä½¿ç”¨åŸå§‹æ£€æµ‹åˆ—è¡¨
            best_iou = 0
            best_match = None
            for orig_det in original_detections:
                iou = GeometryUtils.calculate_iou(tlbr, orig_det['box'])
                if iou > best_iou and iou > 0.1:
                    best_iou = iou
                    best_match = orig_det
            
            if best_match:
                class_name = best_match['class']
            else:
                # è·ç¦»åŒ¹é…
                min_distance = float('inf')
                for orig_det in original_detections:
                    orig_center = [(orig_det['box'][0] + orig_det['box'][2]) / 2, 
                                  (orig_det['box'][1] + orig_det['box'][3]) / 2]
                    track_center = [(tlbr[0] + tlbr[2]) / 2, (tlbr[1] + tlbr[3]) / 2]
                    distance = ((orig_center[0] - track_center[0]) ** 2 + 
                               (orig_center[1] - track_center[1]) ** 2) ** 0.5
                    
                    if distance < min_distance and distance < 100:
                        min_distance = distance
                        class_name = orig_det['class']
        
        # è®¡ç®—ç›®æ ‡åº•éƒ¨ä¸­å¿ƒç‚¹ï¼ˆç”¨äºèåˆåŒºåŸŸåˆ¤æ–­ï¼‰
        center_x = int((tlbr[0] + tlbr[2]) / 2)
        center_y = int(tlbr[3])
        pixel_point = (center_x, center_y)
        
        # æ£€æŸ¥æ˜¯å¦åœ¨é›·è§†èåˆåŒºåŸŸå†…
        in_fusion_area = GeometryUtils.is_in_radar_vision_fusion_area(pixel_point, camera_id)
        
        detection = {
            'box': tlbr,
            'confidence': track.score,
            'class': class_name,  # ä¿ç•™åŸå§‹ç±»åˆ«ä¿¡æ¯
            'track_id': track.track_id,
            'local_id': track.track_id,
            'center_point': [(tlbr[0] + tlbr[2]) / 2, (tlbr[1] + tlbr[3]) / 2],
            'timestamp': result.get('timestamp', time.time()),
            'camera_id': camera_id,
            'in_fusion_area': in_fusion_area  # æ–°å¢ï¼šæ ‡è®°æ˜¯å¦åœ¨èåˆåŒºåŸŸå†…
        }
        tracked_detections.append(detection)
    
    return tracked_detections

# ğŸ”§ ä¿®æ”¹ï¼šä½¿ç”¨åˆå§‹è§†é¢‘æ—¶é—´ + frame_id/fps è®¡ç®—æ—¶é—´æˆ³
def create_sdk_worker_process(camera_id: int, video_path: str, result_queue: multiprocessing.Queue):
    """åˆ›å»ºå¹¶è¿è¡Œä¸€ä¸ªç‹¬ç«‹çš„ SDK æ¨ç†å­è¿›ç¨‹ (ç”Ÿäº§è€…)"""
    
    # ç¡®ä¿å­è¿›ç¨‹èƒ½æ‰¾åˆ° SDKinfer æ¨¡å—
    from SDKinfer import yolov5_SDK, infer_process_attr
    from Basic import Config
    
    try:
        logger.info(f"Camera{camera_id} å­è¿›ç¨‹å¯åŠ¨")
        logger.info(f"Camera{camera_id} è§†é¢‘æº: {video_path[:80] if len(video_path) > 80 else video_path}")
        
        attr = infer_process_attr()
        attr.url = video_path
        attr.device_id = 0
        attr.chan_id = camera_id - 1
        attr.plugin_path = "/usr/local/lynxi/sdk/sdk-samples/plugin/obj/libYolov5Plugin.so"
        attr.model_path = "/root/yolov5-7.0_lyngor1.17.0/best_yolov5s_onnx/Net_0/"
        attr.show_type = 2
        attr.output_path = ""  # ğŸ”§ å‚è€ƒ main_1015.pyï¼šè®¾ç½®è¾“å‡ºè·¯å¾„
        # ğŸ”§ ä¿®å¤ï¼šåˆå§‹åŒ– video_frame ä¸ºé˜Ÿåˆ—å¯¹è±¡ï¼Œé¿å… 'int' object has no attribute 'queue' é”™è¯¯
        attr.video_frame = queue.Queue(10)
        
        logger.info(f"Camera{camera_id} åˆå§‹åŒ–yolov5_SDK")
        logger.info(f"Camera{camera_id} å¦‚æœå‡ºç° 'av.open' é”™è¯¯ï¼Œè¯·æ£€æŸ¥RTSP URL/ç½‘ç»œ/è§†é¢‘æ–‡ä»¶")
        
        # ğŸ”§ ä»é…ç½®ä¸­è·å–åˆå§‹æ—¶é—´å’Œfps
        start_datetime_str = Config.CAMERA_START_DATETIMES.get(camera_id)
        fps = Config.FPS
        
        # æ³¨æ„ï¼šSDKåˆå§‹åŒ–å¯èƒ½ä¼šåœ¨è¿™é‡Œå¤±è´¥ï¼Œå¦‚æœRTSPè¿æ¥ä¸å¯ç”¨
        worker = yolov5_SDK(attr, result_queue, start_datetime_str=start_datetime_str, fps=fps) 
        logger.info(f"Camera{camera_id} yolov5_SDKåˆå§‹åŒ–æˆåŠŸ")
        
        # ğŸ”§ å‚è€ƒ main_1015.pyï¼šæ›´æ–°ç±»åˆ«åç§°åˆ°æ’ä»¶ä¸­
        class_name_path = "/usr/local/lynxi/sdk/sdk-samples/data/class.txt"
        if os.path.exists(class_name_path):
            worker.update_class_name(class_name_path)
            logger.info(f"Camera{camera_id} ç±»åˆ«åç§°å·²æ›´æ–°")
        
        logger.info(f"Camera{camera_id} å¼€å§‹è¿è¡ŒSDKæ¨ç†...")
        worker.run(cancel_flag)
        logger.info(f"Camera{camera_id} å­è¿›ç¨‹æ­£å¸¸é€€å‡º")
        
    except Exception as e:
        error_msg = str(e)
        logger.error(f"Camera{camera_id} SDKè¿›ç¨‹å¤±è´¥: {error_msg}")
        import traceback
        traceback.print_exc()
        # ç¡®ä¿è¿›ç¨‹èƒ½é€€å‡º
        os._exit(1)
        
# --- ä¸»ç¨‹åº (æ¶ˆè´¹è€…ï¼Œèåˆä¸åŒæ­¥) ---

if __name__ == "__main__":
    
    # 1. é…ç½®
    logger.info("="*60)
    logger.info("ç¨‹åºå¼€å§‹å¯åŠ¨...")
    logger.info("="*60)
    
    # å°è¯•ä»é…ç½®æ–‡ä»¶è¯»å–RTSP URLsï¼Œå¤±è´¥åˆ™ä½¿ç”¨æœ¬åœ°è§†é¢‘æ–‡ä»¶
    video_paths = {}
    if RTSP_MQTT_AVAILABLE:
        try:
            config_reader = ConfigReader()
            enabled_cameras = config_reader.get_enabled_cameras()
            
            if enabled_cameras and len(enabled_cameras) >= 3:
                for i, camera in enumerate(enabled_cameras[:3], 1):
                    video_paths[i] = camera['rtsp_url']
                    logger.info(f"æ‘„åƒå¤´{i}: {camera['name']} - {camera['rtsp_url']}")
                logger.info("ä½¿ç”¨RTSPæµä½œä¸ºè¾“å…¥")
            else:
                logger.warning("é…ç½®æ–‡ä»¶ä¸­æ‘„åƒå¤´æ•°é‡ä¸è¶³ï¼Œå›é€€åˆ°æœ¬åœ°è§†é¢‘æ–‡ä»¶")
                raise Exception("é…ç½®ä¸è¶³")
        except Exception as e:
            logger.warning(f"è¯»å–RTSPé…ç½®å¤±è´¥: {e}, ä½¿ç”¨æœ¬åœ°è§†é¢‘æ–‡ä»¶")
            RTSP_MQTT_AVAILABLE = False
    
    # å›é€€åˆ°æœ¬åœ°è§†é¢‘æ–‡ä»¶
    if not RTSP_MQTT_AVAILABLE or not video_paths:
        logger.info("ä½¿ç”¨æœ¬åœ°è§†é¢‘æ–‡ä»¶")
        # è®¾ç½®é»˜è®¤çš„æœ¬åœ°è§†é¢‘æ–‡ä»¶è·¯å¾„ - ä½¿ç”¨å®é™…å­˜åœ¨çš„è§†é¢‘æ–‡ä»¶
        video_paths = {
            1: "/root/yolov5-7.0_lyngor1.17.0/videos/test_121.mp4",
            2: "/root/yolov5-7.0_lyngor1.17.0/videos/test_122.mp4",
            3: "/root/yolov5-7.0_lyngor1.17.0/videos/test_123.mp4"
        }
        
        # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        for cam_id, video_path in video_paths.items():
            if not os.path.exists(video_path):
                logger.error(f"Camera{cam_id} è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
                logger.error("è¯·ç¡®ä¿è§†é¢‘æ–‡ä»¶å­˜åœ¨æˆ–æä¾›æ­£ç¡®çš„RTSPæºé…ç½®")
                sys.exit(1)
            else:
                logger.info(f"Camera{cam_id}: {video_path}")
    
    detect_areas = {
        1: [np.array([[0, 720], [226, 324], [576, 77], [714, 77], [1278, 390], [1280, 720]], dtype=np.int32),
            np.array([[218,324], [472,149], [366,141], [48,312]], dtype=np.int32)],
        2: [np.array([[0, 503], [0, 714], [1280, 720], [1280, 410], [800, 128],[471,133]], dtype=np.int32)],
        3: [np.array([[70, 720], [1030, 720], [934, 166], [90, 166]], dtype=np.int32)]}
        
    signal.signal(signal.SIGINT, cancel_process)
    
    # 2. åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
    # ã€æ–°å¢ã€‘æŒ‡å®šèåˆç­–ç•¥ï¼š'original' æˆ– 'improved'
    fusion_strategy = "improved"  # å¯æ”¹ä¸º "original" ä½¿ç”¨åŸå§‹èåˆé€»è¾‘
    fusion_system = CrossCameraFusion(fusion_strategy=fusion_strategy)
    perf_monitor = PerformanceMonitor()
    logger.info(f"ä½¿ç”¨èåˆç­–ç•¥: {fusion_strategy}")
    
    # 2.0 åˆå§‹åŒ–æ‘„åƒå¤´ç®¡ç†å™¨
    camera_manager = CameraManager(video_paths, cancel_flag)
    queues = camera_manager.create_queues(maxsize=10)
    
    # 2.1 åˆå§‹åŒ–é›·è¾¾èåˆæ¨¡å—
    logger.info("åˆå§‹åŒ–é›·è¾¾èåˆæ¨¡å—")
    radar_fusion_enabled = False
    radar_data_loader = None
    radar_fusion_processors = {}  # æŒ‰æ‘„åƒå¤´å­˜å‚¨èåˆå¤„ç†å™¨
    
    # é›·è¾¾æ•°æ®æ–‡ä»¶è·¯å¾„ (å¯é…ç½®)
    radar_data_path = '/root/yolov5-7.0_lyngor1.17.0/project-simple-video/videos/radar_data.jsonl'
        
    try:
        if os.path.exists(radar_data_path):
            # åˆå§‹åŒ–é›·è¾¾æ•°æ®åŠ è½½å™¨
            radar_data_loader = RadarDataLoader(radar_data_path)
            if radar_data_loader.load():
                # ä¸ºæ¯ä¸ªæ‘„åƒå¤´åˆå§‹åŒ–ç‹¬ç«‹çš„èåˆå¤„ç†å™¨
                for camera_id in [1, 2, 3]:
                    radar_fusion_processors[camera_id] = RadarVisionFusionProcessor(
                        fusion_area_geo=None,  # ä½¿ç”¨èåˆåŒºåŸŸåˆ¤æ–­å·²åœ¨GlobalIDåˆ†é…æ—¶å®Œæˆ
                        lat_offset=-0.00000165,
                        lon_offset=0.0000450
                    )
                    
                    # å°†è¯¥æ‘„åƒå¤´çš„é›·è¾¾æ•°æ®æ·»åŠ åˆ°å¯¹åº”çš„å¤„ç†å™¨
                    camera_timestamps = radar_data_loader.get_camera_timestamps(camera_id)
                    for ts in camera_timestamps:
                        radar_objs = radar_data_loader.get_radar_data_by_camera(camera_id, ts)
                        radar_fusion_processors[camera_id].add_radar_data(ts, radar_objs)
                    
                    logger.info(f"C{camera_id} é›·è¾¾èåˆå¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ, é›·è¾¾æ•°æ®å¸§æ•°: {len(camera_timestamps)}")
                
                radar_fusion_enabled = True
                logger.info(f"é›·è¾¾èåˆæ¨¡å—åˆå§‹åŒ–æˆåŠŸ")
            else:
                logger.warning("é›·è¾¾æ•°æ®åŠ è½½å¤±è´¥ï¼Œå°†ä¸ä½¿ç”¨é›·è¾¾èåˆ")
        else:
            logger.warning(f"é›·è¾¾æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {radar_data_path}")
            logger.warning("å°†ä¸ä½¿ç”¨é›·è¾¾èåˆåŠŸèƒ½")
    except Exception as e:
        logger.warning(f"é›·è¾¾èåˆæ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")
        logger.warning("å°†ä¸ä½¿ç”¨é›·è¾¾èåˆåŠŸèƒ½")
        radar_fusion_enabled = False
    
    # DEBUG: è·Ÿè¸ªå™¨è¾“å…¥ç»Ÿè®¡
    tracker_input_stats = {1: {'total': 0, 'empty': 0, 'non_empty': 0, 'total_dets': 0}, 
                          2: {'total': 0, 'empty': 0, 'non_empty': 0, 'total_dets': 0},
                          3: {'total': 0, 'empty': 0, 'non_empty': 0, 'total_dets': 0}}
    
    # åˆå§‹åŒ–MQTTå‘å¸ƒå™¨
    mqtt_publisher = None
    if RTSP_MQTT_AVAILABLE:
        try:
            mqtt_publisher = MqttPublisher("config/mqtt_config.ini")
            mqtt_publisher.connect()
            logger.info("MQTTå‘å¸ƒå™¨å·²è¿æ¥")
        except Exception as e:
            logger.warning(f"MQTTè¿æ¥å¤±è´¥: {e}, å°†ä½¿ç”¨JSONæ–‡ä»¶ä¿å­˜")
            mqtt_publisher = None
    
    class TrackerArgs: # æ–°ByteTracker æ‰€éœ€å‚æ•°
        def __init__(self):
            self.track_thresh = 0.5    # è·Ÿè¸ªç½®ä¿¡åº¦é˜ˆå€¼ï¼Œè¿‡ä½ä¼šå¯¼è‡´å™ªå£°
            self.track_buffer = 30     # å¢åŠ ç¼“å†²åŒºå¤§å°ä»¥ä¿ç•™è½¨è¿¹å†å²
            self.match_thresh = 0.8    # åŒ¹é…é˜ˆå€¼
            self.mot20 = False         # MOT20æ•°æ®é›†æ ‡å¿—
    
    tracker_args = TrackerArgs()
    trackers = {i: BYTETracker(tracker_args, frame_rate=Config.FPS) for i in [1, 2, 3]}
    logger.info("å·²å¯ç”¨ä¼˜åŒ–ç‰ˆByteTracker - äº¤æ›¿è·Ÿè¸ªæ¨¡å¼") 

    # 3. åˆ›å»ºå¹¶å¯åŠ¨ SDK æ¨ç†è¿›ç¨‹ (ç”Ÿäº§è€…)
    # ä½¿ç”¨ CameraManager å¤„ç†RTSPè¿æ¥æµ‹è¯•å’Œè¿›ç¨‹å¯åŠ¨
    camera_manager.test_all_rtsp_connections()
    camera_manager.start_all_cameras(create_sdk_worker_process)
    processes = camera_manager.get_processes()

    # 3.5. å¯åŠ¨é¢„çƒ­é˜¶æ®µï¼šç­‰å¾…æ‰€æœ‰æ‘„åƒå¤´é˜Ÿåˆ—éƒ½æœ‰æ•°æ®
    preheat_success = camera_manager.wait_for_preheat(timeout=30)


    # 4. ä¸»å¾ªç¯ï¼šæ—¶é—´æˆ³èåˆé€»è¾‘ (æ¶ˆè´¹è€…)
    
    # ğŸ”§ æ—¶é—´æˆ³é…ç½®ï¼šå®Œå…¨åŸºäºæ—¶é—´æˆ³åŒæ­¥ï¼Œä¸ä¾èµ–å¸§å·
    logger.info("åŒæ­¥æ–¹å¼: çº¯æ—¶é—´æˆ³åŒæ­¥ (ä¸ä¾èµ–å¸§å·)")
    
    # ğŸ”§ æ”¹é€ ï¼šç§»é™¤å¸§åŒæ­¥ï¼Œæ”¹ä¸ºå•è·¯ç‹¬ç«‹å¤„ç†
    logger.info("èåˆä¸»å¾ªç¯å¯åŠ¨ - å•è·¯å¤„ç†æ¨¡å¼")
    logger.info("å¤„ç†æ¨¡å¼: å•è·¯ç‹¬ç«‹å¤„ç† + åæœŸä¸‰è·¯åŒ¹é…")
    logger.info("="*60)
    
    # åˆå§‹åŒ–å•è·¯ç»“æœå­˜å‚¨
    camera_results = {1: [], 2: [], 3: []}  # å­˜å‚¨æ¯ä¸ªæ‘„åƒå¤´çš„å¤„ç†ç»“æœ

    try:
        current_frame = 0
        radar_id_map = {}  # å…¨å±€radar_id_map
        
        while not cancel_flag.value:
            
            # A. ä»æ‰€æœ‰é˜Ÿåˆ—ä¸­è·å–ç»“æœï¼Œå•è·¯ç‹¬ç«‹å¤„ç†
            perf_monitor.start_timer('queue_processing')
            current_frame_results = {}
            
            for camera_id in [1, 2, 3]:
                queue_size = queues[camera_id].qsize()
                perf_monitor.record_queue_stats(camera_id, queue_size, 'read')
                
                try:
                    # éé˜»å¡è·å–å•ä¸ªå¸§
                    result = queues[camera_id].get_nowait()
                    perf_monitor.add_counter('queue_operations')
                    current_frame_results[camera_id] = result
                except multiprocessing.queues.Empty:
                    # è¯¥æ‘„åƒå¤´æš‚æ— æ–°å¸§ï¼Œè·³è¿‡
                    pass
                except Exception as e:
                    logger.error(f"C{camera_id} é˜Ÿåˆ—è¯»å–å¼‚å¸¸: {e}")
            
            queue_processing_time = perf_monitor.end_timer('queue_processing')
            
            # å¦‚æœæ²¡æœ‰ä»»ä½•æ‘„åƒå¤´æœ‰æ–°å¸§ï¼ŒçŸ­æš‚ç­‰å¾…
            if not current_frame_results:
                time.sleep(0.01)
                continue
            
            # å¢åŠ å¸§è®¡æ•°
            current_frame += 1
            
            # ğŸ“Š æ€§èƒ½ç›‘æ§ï¼šè®°å½•æ¯å¸§å¤„ç†æƒ…å†µ
            perf_monitor.add_counter('frames_processed')
                
            all_frame_detections = []
            perf_monitor.start_timer('frame_processing')
            
            for camera_id, result in current_frame_results.items():
                perf_monitor.start_timer(f'camera_{camera_id}_processing')
                
                # 1. ç±»åˆ«è¿‡æ»¤ï¼šåªè·Ÿè¸ªè½¦è¾†ï¼Œæ’é™¤éè½¦è¾†ç±»åˆ«
                raw_detections = [d for d in result['detections'] 
                                if d['class'] in Config.VEHICLE_CLASSES and d['class'] not in Config.EXCLUDE_CLASSES]
                # ğŸ“Š æ€§èƒ½ç›‘æ§ï¼šè®°å½•æ£€æµ‹æ•°é‡
                perf_monitor.add_counter('detections_processed', len(raw_detections))
                
                # 2. NMS å’Œ è·Ÿè¸ªå™¨è¾“å…¥æ ¼å¼è½¬æ¢
                # æ€§èƒ½ä¼˜åŒ–ï¼šæ‰¹é‡æ•°æ®è½¬æ¢ï¼Œé¿å…å¾ªç¯ï¼Œå‡å°‘2-3mså¤„ç†æ—¶é—´
                perf_monitor.start_timer('nms_processing')
                det_for_nms = [{'box': d['box'], 'confidence': d['confidence'], 'class': d['class']} for d in raw_detections]
                nms_detections = DetectionUtils.non_max_suppression(det_for_nms)
                perf_monitor.end_timer('nms_processing')
                
                # 3. åŒºåŸŸè¿‡æ»¤ (å…ˆè¿‡æ»¤åè·Ÿè¸ª)
                perf_monitor.start_timer('area_filtering')
                filtered_nms_detections = filter_by_detect_areas(nms_detections, detect_areas[camera_id])
                perf_monitor.end_timer('area_filtering')
                
                # 4. ä½¿ç”¨æ‰¹é‡å¤„ç†å‡½æ•°ï¼Œæå‡æ€§èƒ½
                perf_monitor.start_timer('tracker_input_preparation')
                tracker_input_tensor, box_to_class = batch_prepare_tracker_input(filtered_nms_detections)
                perf_monitor.end_timer('tracker_input_preparation')
                
                # é™åˆ¶æœ€å¤§è·Ÿè¸ªç›®æ ‡æ•°é‡ï¼Œé¿å…åŒˆç‰™åˆ©ç®—æ³•æ€§èƒ½é—®é¢˜
                if len(tracker_input_tensor) > 50:
                    tracker_input_tensor = tracker_input_tensor[:50]
                    logger.warning(f"C{camera_id} ç›®æ ‡æ•°é‡è¿‡å¤š({len(filtered_nms_detections)})ï¼Œé™åˆ¶ä¸º50ä¸ª")

                # 5. å±€éƒ¨è·Ÿè¸ª (BYTETracker)
                perf_monitor.start_timer(f'tracker_update_{camera_id}')
                img_info = [Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH]  # [height, width]
                img_size = (Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH)  # (width, height)
                
                # DEBUG: æ£€æŸ¥trackerè¾“å…¥
                debug_input_count = len(tracker_input_tensor) if tracker_input_tensor is not None else 0
                tracker_input_stats[camera_id]['total'] += 1
                tracker_input_stats[camera_id]['total_dets'] += debug_input_count
                if debug_input_count == 0:
                    tracker_input_stats[camera_id]['empty'] += 1
                else:
                    tracker_input_stats[camera_id]['non_empty'] += 1
                
                # æ‰“å°è·Ÿè¸ªå‰çš„è°ƒè¯•ä¿¡æ¯
                # ğŸ”§ ä¼˜åŒ–ï¼šDEBUGè¾“å‡ºä»æ¯100å¸§æ”¹ä¸ºæ¯500å¸§
                if current_frame % 500 == 0:
                    logger.debug(f"C{camera_id} F{current_frame} è·Ÿè¸ªå‰: åŸå§‹={len(raw_detections)}, NMS={len(nms_detections)}, è¿‡æ»¤={len(filtered_nms_detections)}, è¾“å…¥={debug_input_count}")
                
                tracked_objects = trackers[camera_id].update(tracker_input_tensor, img_info, img_size)
                tracker_time = perf_monitor.end_timer(f'tracker_update_{camera_id}')
                # ğŸ“Š æ€§èƒ½ç›‘æ§ï¼šè®°å½•æ¯æ¬¡è·Ÿè¸ªå™¨æ›´æ–°
                perf_monitor.add_counter('tracker_updates')
                
                perf_monitor.record_fusion_stats(f'tracker_update_{camera_id}', tracker_time, {
                    'input_count': len(filtered_nms_detections),
                    'output_count': len(tracked_objects)
                })

                # 6. è·Ÿè¸ªç»“æœè½¬æ¢ (æ€§èƒ½ä¼˜åŒ–ç‰ˆ)
                # ä¼˜åŒ–ç‚¹ï¼šä¿ç•™åŸå§‹ç±»åˆ«ä¿¡æ¯ï¼Œæå‡è·Ÿè¸ªç²¾åº¦ï¼Œä½¿ç”¨box_to_classæ˜ å°„ âœ… FIX
                tracked_detections = batch_convert_track_results(tracked_objects, result, camera_id, current_frame, filtered_nms_detections, box_to_class)
                
                # 7. è·¨æ‘„åƒå¤´èåˆå¤„ç† - æ–°çš„èåˆé€»è¾‘
                # ä»åŒæ­¥å¸§ä¸­è·å–æ—¶é—´æˆ³
                timestamp = result.get('timestamp', None)
                global_targets, local_targets = fusion_system.process_detections(tracked_detections, camera_id, timestamp, perf_monitor)
                
                # å­˜å‚¨æ­¤å¸§çš„å…¨å±€å’Œæœ¬åœ°ç›®æ ‡
                all_frame_detections.append({
                    'camera_id': camera_id,
                    'global_targets': global_targets,
                    'local_targets': local_targets
                })
                
                camera_processing_time = perf_monitor.end_timer(f'camera_{camera_id}_processing')
                # ğŸ“Š æ€§èƒ½ç›‘æ§ï¼šè®°å½•æ¯å¸§çš„æ‘„åƒå¤´å¤„ç†ç»Ÿè®¡
                perf_monitor.record_fusion_stats(f'camera_{camera_id}_processing', camera_processing_time, {
                    'raw_detections': len(raw_detections),
                    'tracked_detections': len(tracked_detections),
                    'filtered_detections': len(filtered_nms_detections),
                    'global_targets': len(global_targets),
                    'local_targets': len(local_targets)
                })
            
            frame_processing_time = perf_monitor.end_timer('frame_processing')
            
            # æ”¶é›†æ‰€æœ‰å…¨å±€å’Œæœ¬åœ°ç›®æ ‡
            all_global_targets = []
            all_local_targets = []
            for frame_data in all_frame_detections:
                all_global_targets.extend(frame_data['global_targets'])
                all_local_targets.extend(frame_data['local_targets'])
            
            # C. è·¨æ‘„åƒå¤´èåˆï¼šåŒ¹é…å…¨å±€å’Œæœ¬åœ°ç›®æ ‡
            perf_monitor.start_timer('matching_processing')
            active_global_targets = list(fusion_system.global_targets.values())
            fusion_system._perform_matching(all_local_targets, active_global_targets, perf_monitor)
            
            # æ›´æ–°å…¨å±€çŠ¶æ€
            fusion_system.update_global_state(all_global_targets, all_local_targets)
            matching_time = perf_monitor.end_timer('matching_processing')

            # D. é›·è¾¾èåˆå¤„ç† (æŒ‰æ‘„åƒå¤´åŒæ­¥èåˆ)
            radar_id_map = {}
            if radar_fusion_enabled and radar_fusion_processors:
                perf_monitor.start_timer('radar_fusion_processing')
                
                # æŒ‰æ‘„åƒå¤´è¿›è¡Œé›·è¾¾èåˆ
                for camera_id in [1, 2, 3]:
                    if camera_id not in radar_fusion_processors:
                        continue
                    
                    # æ”¶é›†è¯¥æ‘„åƒå¤´çš„æ‰€æœ‰ç›®æ ‡
                    vision_objects = []
                    
                    # å¤„ç†å…¨å±€ç›®æ ‡
                    for global_target in all_global_targets:
                        if global_target.camera_id != camera_id:
                            continue
                        if not global_target.bev_trajectory:
                            continue
                        current_bev = global_target.bev_trajectory[-1]
                        if current_bev[0] == 0.0 and current_bev[1] == 0.0:
                            continue
                        
                        geo_result = GeometryUtils.bev_to_geo(current_bev[0], current_bev[1])
                        if not geo_result:
                            continue
                        
                        lng, lat = geo_result
                        confidence = global_target.confidence_history[-1] if global_target.confidence_history else 0.0
                        
                        vision_obj = OutputObject(
                            timestamp="",
                            cameraid=global_target.camera_id,
                            type_name=global_target.class_name,
                            confidence=confidence,
                            track_id=global_target.global_id,
                            lon=lng,
                            lat=lat
                        )
                        vision_objects.append(vision_obj)
                    
                    # å¤„ç†æœ¬åœ°ç›®æ ‡ (å·²åŒ¹é…çš„)
                    for local_target in all_local_targets:
                        if local_target.camera_id != camera_id:
                            continue
                        if not local_target.matched_global_id:
                            continue
                        
                        if local_target.current_bev_pos[0] == 0.0 and local_target.current_bev_pos[1] == 0.0:
                            continue
                        
                        geo_result = GeometryUtils.bev_to_geo(local_target.current_bev_pos[0], local_target.current_bev_pos[1])
                        if not geo_result:
                            continue
                        
                        lng, lat = geo_result
                        
                        # æ£€æŸ¥æ˜¯å¦å·²ç»æ·»åŠ è¿‡è¿™ä¸ª global_id
                        if not any(v.track_id == local_target.matched_global_id for v in vision_objects):
                            vision_obj = OutputObject(
                                timestamp="",
                                cameraid=local_target.camera_id,
                                type_name=local_target.class_name,
                                confidence=local_target.confidence,
                                track_id=local_target.matched_global_id,
                                lon=lng,
                                lat=lat
                            )
                            vision_objects.append(vision_obj)
                    
                    # æ‰§è¡Œè¯¥æ‘„åƒå¤´çš„é›·è¾¾èåˆ - ä½¿ç”¨åŸå§‹æ—¶é—´æˆ³
                    if vision_objects:
                        # è·å–è¯¥æ‘„åƒå¤´çš„åŸå§‹æ—¶é—´æˆ³
                        if camera_id in current_frame_results:
                            result = current_frame_results[camera_id]
                            original_timestamp = result.get('timestamp', time.time())
                        else:
                            # å¦‚æœæ²¡æœ‰è¯¥æ‘„åƒå¤´çš„ç»“æœï¼Œä½¿ç”¨å½“å‰æ—¶é—´
                            logger.warning(f"C{camera_id} æ²¡æœ‰å½“å‰å¸§ç»“æœï¼Œä½¿ç”¨å½“å‰æ—¶é—´ä½œä¸ºæ—¶é—´æˆ³")
                            original_timestamp = time.time()
                        if isinstance(original_timestamp, str):
                            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œéœ€è¦è½¬æ¢ä¸ºæµ®ç‚¹æ•°
                            # æ³¨æ„ï¼šæ—¶é—´æˆ³æ ¼å¼æ˜¯ 'YYYY-MM-DD HH:MM:SS.mmm' (3ä½æ¯«ç§’ï¼Œä¸æ˜¯6ä½å¾®ç§’)
                            try:
                                from datetime import datetime
                                # æ–¹æ³•1ï¼šå…ˆå°è¯•3ä½æ¯«ç§’æ ¼å¼
                                try:
                                    dt = datetime.strptime(original_timestamp, '%Y-%m-%d %H:%M:%S.%f')
                                except ValueError:
                                    # æ–¹æ³•2ï¼šå¦‚æœå¤±è´¥ï¼Œè¯´æ˜å¯èƒ½æ˜¯3ä½æ¯«ç§’ï¼Œéœ€è¦è¡¥å……åˆ°6ä½
                                    # åˆ†å‰²ç§’å’Œæ¯«ç§’éƒ¨åˆ†
                                    parts = original_timestamp.split('.')
                                    if len(parts) == 2:
                                        second_part = parts[0]
                                        ms_part = parts[1]
                                        # è¡¥å……åˆ°6ä½å¾®ç§’
                                        us_part = ms_part.ljust(6, '0')
                                        ts_with_us = f"{second_part}.{us_part}"
                                        dt = datetime.strptime(ts_with_us, '%Y-%m-%d %H:%M:%S.%f')
                                    else:
                                        raise ValueError("æ—¶é—´æˆ³æ ¼å¼é”™è¯¯")
                                original_timestamp = dt.timestamp()
                            except Exception as e:
                                logger.warning(f"æ—¶é—´æˆ³è½¬æ¢å¤±è´¥: {original_timestamp}, é”™è¯¯: {e}")
                                original_timestamp = time.time()
                        
                        updated_vision_objects = radar_fusion_processors[camera_id].process_frame(original_timestamp, vision_objects)
                        
                        # æ„å»º radar_id_map (keyä½¿ç”¨global_idï¼Œå³vision_obj.track_id)
                        # vision_obj.track_id å·²ç»æ˜¯ global_idï¼ˆè§ä¸Šé¢åˆ›å»ºvision_objectsçš„ä»£ç ï¼‰
                        for vision_obj in updated_vision_objects:
                            if vision_obj.radar_id is not None:
                                # ç›´æ¥ä½¿ç”¨ track_id ä½œä¸º keyï¼ˆtrack_id å°±æ˜¯ global_idï¼‰
                                radar_id_map[vision_obj.track_id] = vision_obj.radar_id
                                if current_frame % 100 == 0:
                                    logger.debug(f"Frame {current_frame} C{camera_id}: é›·è¾¾IDæ˜ å°„ track_id={vision_obj.track_id} -> radar_id={vision_obj.radar_id}")
                        
                        # ç»Ÿè®¡ä¿¡æ¯
                        matched_count = sum(1 for v in updated_vision_objects if v.radar_id is not None)
                        if current_frame % 100 == 0 and matched_count > 0:
                            logger.info(f"Frame {current_frame} C{camera_id}: é›·è¾¾åŒ¹é… {matched_count}/{len(updated_vision_objects)} ä¸ªç›®æ ‡ï¼Œradar_id_mapå¤§å°={len(radar_id_map)}")
                
                perf_monitor.end_timer('radar_fusion_processing')
            
            # D.1 å­˜å‚¨å•è·¯å¤„ç†ç»“æœï¼Œç”¨äºåæœŸä¸‰è·¯åŒ¹é…
            perf_monitor.start_timer('store_single_camera_results')
            for camera_id in [1, 2, 3]:
                if camera_id in current_frame_results:
                    result = current_frame_results[camera_id]
                    original_timestamp = result.get('timestamp', time.time())
                    
                    # è·å–è¯¥æ‘„åƒå¤´çš„æœ¬åœ°ç›®æ ‡
                    camera_local_targets = [t for t in all_local_targets if t.camera_id == camera_id]
                    
                    # è·å–è¯¥æ‘„åƒå¤´çš„radar_ids
                    camera_radar_ids = {t.local_id: radar_id_map.get(t.local_id) for t in camera_local_targets}
                    
                    # å­˜å‚¨ç»“æœ
                    fusion_system.store_single_camera_result(camera_id, original_timestamp, camera_local_targets, camera_radar_ids)
            
            perf_monitor.end_timer('store_single_camera_results')
            
            # D.2 å®šæœŸè¿›è¡Œä¸‰è·¯åŒ¹é…ï¼ˆæ¯å¤„ç†100å¸§ï¼‰
            if current_frame > 0 and current_frame % 100 == 0:
                perf_monitor.start_timer('cross_camera_matching')
                try:
                    global_targets_from_matching, unmatched_local_targets = fusion_system.match_cross_camera_targets(time_window=0.5)
                    if global_targets_from_matching:
                        logger.info(f"Frame {current_frame}: ä¸‰è·¯åŒ¹é…æ‰¾åˆ° {len(global_targets_from_matching)} ä¸ªå…¨å±€ç›®æ ‡")
                except Exception as e:
                    logger.error(f"ä¸‰è·¯åŒ¹é…å¼‚å¸¸: {e}")
                perf_monitor.end_timer('cross_camera_matching')
            
            # E. ç”ŸæˆJSONæ•°æ®å¹¶å°è¯•å‘é€MQTT
            perf_monitor.start_timer('json_mqtt_processing')
            
            # è·å–å½“å‰å¸§çš„æ—¶é—´æˆ³ï¼ˆä½¿ç”¨æœ€æ–°çš„æ‘„åƒå¤´æ—¶é—´æˆ³ï¼‰
            frame_timestamp = None
            for camera_id in [1, 2, 3]:
                if camera_id in current_frame_results:
                    result = current_frame_results[camera_id]
                    ts = result.get('timestamp', None)
                    if ts is not None:
                        frame_timestamp = ts
                        break
            
            perf_monitor.start_timer('json_generation')
            json_data = fusion_system.generate_json_data(all_global_targets, all_local_targets, radar_id_map, frame_timestamp)
            perf_monitor.end_timer('json_generation')
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºå¸§ï¼ˆparticipantsä¸ºç©ºï¼‰
            participants = json_data.get('participant', [])
            if len(participants) == 0:
                # ç©ºå¸§ä¸è¾“å‡ºï¼Œè·³è¿‡MQTTå‘é€å’ŒJSONä¿å­˜
                perf_monitor.end_timer('json_mqtt_processing')
                fusion_system.next_frame()
                continue
            
            mqtt_sent = False
            if mqtt_publisher:
                perf_monitor.start_timer('mqtt_publish')
                try:
                    mqtt_sent = mqtt_publisher.publish_rsm(participants)
                    if mqtt_sent:
                        # ğŸ“Š æ€§èƒ½ç›‘æ§ï¼šè®°å½•MQTTæˆåŠŸå‘é€
                        perf_monitor.add_counter('mqtt_sends')
                    else:
                        # ğŸ“Š æ€§èƒ½ç›‘æ§ï¼šè®°å½•MQTTå‘é€å¤±è´¥
                        perf_monitor.add_counter('mqtt_failures')
                except Exception as e:
                    logger.error(f"MQTTå‘é€å¼‚å¸¸: {e}")
                    perf_monitor.add_counter('mqtt_failures')
                finally:
                    perf_monitor.end_timer('mqtt_publish')
            
            # ğŸ”§ ä¿®å¤ï¼šæ— è®ºMQTTæ˜¯å¦æˆåŠŸï¼Œéƒ½ä¿å­˜JSONæ•°æ®ï¼ˆç”¨äºè°ƒè¯•å’Œå¤‡ä»½ï¼‰
            # åªä¿å­˜éç©ºå¸§
            fusion_system.json_output_data.append(json_data)          
            json_mqtt_time = perf_monitor.end_timer('json_mqtt_processing')       
            fusion_system.next_frame()

            # D. å®šæœŸæŠ¥å‘Šé˜Ÿåˆ—çŠ¶æ€
            if current_frame > 0 and current_frame % 300 == 0:
                queue_sizes = {i: queues[i].qsize() for i in [1, 2, 3]}
                logger.info(f"é˜Ÿåˆ—çŠ¶æ€ (æˆªè‡³å¸§ {current_frame})")
                for cam_id in [1, 2, 3]:
                    logger.info(f"C{cam_id}: é˜Ÿåˆ—å¤§å° {queue_sizes[cam_id]}")
        
        logger.info("æ‰€æœ‰å¤„ç†å®Œæˆ")
        
        # 5. ä¿å­˜èåˆç»“æœï¼ˆæ­£å¸¸é€€å‡ºæ—¶ï¼‰
        try:
            json_count = len(fusion_system.json_output_data) if fusion_system.json_output_data else 0
            logger.info(f"å‡†å¤‡ä¿å­˜ {json_count} å¸§çš„JSONæ•°æ®")
            if json_count > 0:
                fusion_system.save_json_data("output_fusion_refactored.json")
            else:
                logger.warning("JSONæ•°æ®åˆ—è¡¨ä¸ºç©º")
        except Exception as e:
            logger.error(f"ä¿å­˜JSONæ•°æ®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        
        # 6. è¾“å‡ºæœ€ç»ˆå¤„ç†ç»Ÿè®¡
        logger.info("="*60)
        logger.info("æœ€ç»ˆå¤„ç†ç»Ÿè®¡æŠ¥å‘Š")
        
        processed_frames_count = fusion_system.frame_count
        logger.info(f"æˆåŠŸå¤„ç†çš„å¸§æ•°: {processed_frames_count}å¸§")
            
        logger.info("="*60)
        
        # è¾“å‡ºæœ€ç»ˆè·Ÿè¸ªå™¨ä¼˜åŒ–ç»Ÿè®¡
        logger.info("æœ€ç»ˆByteTrackerä¼˜åŒ–ç»Ÿè®¡")
        logger.info("DEBUG - è·Ÿè¸ªå™¨è¾“å…¥ç»Ÿè®¡:")
        for cam_id in [1, 2, 3]:
            stats = tracker_input_stats[cam_id]
            avg_dets = stats['total_dets'] / max(stats['total'], 1)
            logger.info(f"C{cam_id}: è°ƒç”¨{stats['total']}æ¬¡, ç©ºè¾“å…¥{stats['empty']}æ¬¡, éç©º{stats['non_empty']}æ¬¡, æ€»æ£€æµ‹æ•°{stats['total_dets']}, å¹³å‡{avg_dets:.1f}ä¸ª/å¸§")
        
        for cam_id, tracker in trackers.items():
            stats = tracker.get_performance_stats()
            perf_improvement = stats.get('performance_improvement', 1.0)
            avg_tracking_time = stats.get('avg_tracking_time', 0.0)
            avg_prediction_time = stats.get('avg_prediction_time', 0.0)
            logger.info(f"C{cam_id}:")
            logger.info(f"  æ€»å¸§æ•°: {stats['total_frames']}")
            logger.info(f"  è·Ÿè¸ªå¸§: {stats['tracking_frames']} ({stats['tracking_frames']/max(stats['total_frames'],1)*100:.1f}%)")
            logger.info(f"  é¢„æµ‹å¸§: {stats['prediction_only_frames']} ({stats['prediction_only_frames']/max(stats['total_frames'],1)*100:.1f}%)")
            logger.info(f"  æ€§èƒ½æå‡: {perf_improvement:.2f}x")
            logger.info(f"  å¹³å‡è·Ÿè¸ªè€—æ—¶: {avg_tracking_time:.3f}s")
            logger.info(f"  å¹³å‡é¢„æµ‹è€—æ—¶: {avg_prediction_time:.3f}s")
        logger.info("="*60)
        
    except Exception as e:
        logger.error(f"ä¸»ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # ğŸ”§ ä¿®å¤ï¼šåœ¨finallyå—ä¸­ä¿å­˜JSONï¼Œç¡®ä¿å³ä½¿å¼‚å¸¸é€€å‡ºä¹Ÿèƒ½ä¿å­˜æ•°æ®
        logger.info("æ­£åœ¨ä¿å­˜JSONæ•°æ®")
        try:
            json_count = len(fusion_system.json_output_data) if fusion_system.json_output_data else 0
            logger.info(f"å‡†å¤‡ä¿å­˜ {json_count} å¸§çš„JSONæ•°æ®")
            if json_count > 0:
                fusion_system.save_json_data("output_fusion_refactored.json")
            else:
                logger.warning("JSONæ•°æ®åˆ—è¡¨ä¸ºç©ºï¼Œæ²¡æœ‰æ•°æ®å¯ä¿å­˜")
                logger.warning("å¯èƒ½åŸå› : 1) ç¨‹åºå¼‚å¸¸é€€å‡º 2) æ²¡æœ‰æ£€æµ‹åˆ°ç›®æ ‡ 3) æ•°æ®æœªæ­£ç¡®æ·»åŠ ")
        except Exception as e:
            logger.error(f"åœ¨finallyå—ä¸­ä¿å­˜JSONå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        
        # 7. æ¸…ç†èµ„æº
        camera_manager.stop_all_cameras()

        # æ–­å¼€MQTTè¿æ¥
        if mqtt_publisher:
            try:
                mqtt_publisher.disconnect()
                logger.info("MQTTè¿æ¥å·²æ–­å¼€")
            except:
                pass
                
        logger.info("èµ„æºæ¸…ç†å®Œæˆ")